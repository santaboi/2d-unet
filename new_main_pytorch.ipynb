{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.transform as trans\n",
    "import skimage.io as io\n",
    "\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "seed_value= 666\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load data\"\"\"\n",
    "from cfg import *\n",
    "#patients in data_folcder is cinsistent with traget_folder\n",
    "non_name_set = set()\n",
    "PR_name_set = set()\n",
    "name_set = set()\n",
    "total_data_path = [non_T1C_data , non_T1_data , non_Flair_data , non_T2_data , PR_T1C_data , PR_T1_data , PR_Flair_data  , PR_T2_data]\n",
    "count1 = 0\n",
    "for folder_name in total_data_path :\n",
    "    for name in os.listdir(folder_name) :\n",
    "        name = name.strip('.jpg').strip('.json')\n",
    "        if name == 'ipynb_checkpoint' :\n",
    "            continue\n",
    "        name_set.add(name)\n",
    "        if count1 <= 3 :\n",
    "            non_name_set.add(name)\n",
    "        else :\n",
    "            PR_name_set.add(name)\n",
    "    count1 += 1\n",
    "#print(name_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_list = []\n",
    "total_target_list =[] \n",
    "for non_name , pr_name in zip(non_name_set , PR_name_set) :\n",
    "    non_name1 = non_name + \".jpg\"\n",
    "    non_name2 = non_name + \".png\"\n",
    "    pr_name1 = pr_name + \".jpg\"\n",
    "    pr_name2 = pr_name + \".png\"\n",
    "    total_data_list.append(os.path.join(non_T1C_data , non_name1))\n",
    "    total_data_list.append(os.path.join(non_T1_data , non_name1))\n",
    "    total_data_list.append(os.path.join(non_Flair_data , non_name1))\n",
    "    total_data_list.append(os.path.join(non_T2_data , non_name1))\n",
    "    total_target_list.append(os.path.join(non_T1C_target , non_name2))\n",
    "    total_target_list.append(os.path.join(non_T1_target , non_name2))\n",
    "    total_target_list.append(os.path.join(non_Flair_target , non_name2))\n",
    "    total_target_list.append(os.path.join(non_T2_target , non_name2))\n",
    "    \n",
    "    total_data_list.append(os.path.join(PR_T1C_data , pr_name1))\n",
    "    total_data_list.append(os.path.join(PR_T1_data , pr_name1))\n",
    "    total_data_list.append(os.path.join(PR_Flair_data , pr_name1))\n",
    "    total_data_list.append(os.path.join(PR_T2_data , pr_name1))\n",
    "    total_target_list.append(os.path.join(PR_T1C_target , pr_name2))\n",
    "    total_target_list.append(os.path.join(PR_T1_target , pr_name2))\n",
    "    total_target_list.append(os.path.join(PR_Flair_target , pr_name2))\n",
    "    total_target_list.append(os.path.join(PR_T2_target , pr_name2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "75\n",
      "11\n",
      "11\n",
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "train_data_list = total_data_list[0 : int(len(total_data_list)*0.9)] #90%data\n",
    "train_target_list =  total_target_list[0 : int(len(total_target_list)*0.9) ] #90%target\n",
    "\n",
    "test_data_list = total_data_list[int(len(total_data_list)*0.9) : len(total_data_list)] #90%data\n",
    "test_target_list = total_target_list[int(len(total_target_list)*0.9) : len(total_target_list)] #90%target\n",
    "\n",
    "val_img = train_data_list[0 : int(0.2* len(train_data_list))]\n",
    "val_lbl = train_target_list[0 : int(0.2* len(train_target_list))]\n",
    "train_data_list = train_data_list[int(0.2* len(train_data_list)) : ]\n",
    "train_target_list = train_target_list[int(0.2* len(train_target_list)) : ]\n",
    "print(len(train_data_list))\n",
    "print(len(train_target_list))\n",
    "print(len(test_data_list))\n",
    "print(len(test_target_list))\n",
    "print(len(val_img))\n",
    "print(len(val_lbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader , Dataset \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torchvision.transforms as T \n",
    "from torchvision.transforms.functional import hflip , vflip\n",
    "import torch\n",
    "\n",
    "class Total_dataset(Dataset):\n",
    "    def __init__(self, inputs: list, targets: list, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    def __getitem__(self , index : int  , transform = None):\n",
    "        #是否有辦法用path + file name取用data\n",
    "        input_img = self.inputs[index]\n",
    "        target_img = self.targets[index]\n",
    "        \n",
    "        x_data , y_data = cv2.imread(input_img) , cv2.imread(target_img)\n",
    "        \n",
    "        #print(x_data.shape)\n",
    "        #print(y_data.shape)\n",
    "        \n",
    "        \n",
    "        #resize\n",
    "        if x_data.shape != (512 , 512 , 3) :\n",
    "            x_data = cv2.resize(x_data , (512 , 512))\n",
    "        if y_data.shape != (512 , 512 , 3) :\n",
    "            y_data = cv2.resize(y_data , (512 ,512))\n",
    "\n",
    "        # turn to torch (typecasting)\n",
    "\n",
    "        #data augmentaion if true\n",
    "        if self.transform != None : \n",
    "            #x_data , y_data = self.transform(x_data , y_data)\n",
    "            for t in self.transform :\n",
    "                if t == \"T.Normalize([1 , 1 , 1] , [1 , 1 , 1])\" :\n",
    "                    \"\"\"\n",
    "                    x y mean0 tensor(0.2302) tensor(0.0111)\n",
    "                    x y mean1 tensor(0.1842) tensor(0.0111)\n",
    "                    x y mean2 tensor(0.1870) tensor(0.0111)\n",
    "                    x y std0 tensor(0.2334) tensor(0.0737)\n",
    "                    x y std01 tensor(0.1999) tensor(0.0737)\n",
    "                    x y std2 tensor(0.1987) tensor(0.0737)\n",
    "                    \"\"\"\n",
    "                    #normalized with whole dataset mean and std (not batchwise)\n",
    "                    img_normalize = T.Normalize([0.2302 , 0.1842 , 0.1870] , [0.2334 , 0.1999 , 0.1987])\n",
    "                    x_data = img_normalize(x_data)\n",
    "                    label_normalize = T.Normalize([0.0111 , 0.0111 , 0.0111 ] , [0.0737 , 0.0737 , 0.0737]) \n",
    "                    y_data = label_normalize(y_data)\n",
    "                elif t == \"T.RandomHorizontalFlip(p=1)\" :\n",
    "                    if torch.rand(1)< 0.5 :\n",
    "                        x_data = hflip(x_data)\n",
    "                        y_data = hflip(y_data)\n",
    "                elif t == \"T.RandomVerticalFlip(p=1)\" :\n",
    "                    if torch.rand(1)< 0.5 :\n",
    "                        x_data = vflip(x_data)\n",
    "                        y_data = vflip(y_data)\n",
    "                        \n",
    "\n",
    "                elif t == \"T.RandomRotation(degrees=(360 , 360))\" : \n",
    "                    if torch.rand(1)< 0.5 :\n",
    "                        angle = int(torch.rand(1)*360)\n",
    "                        rotate_funct = T.RandomRotation(degrees=(angle, angle))\n",
    "                        x_data = rotate_funct(x_data)\n",
    "                        y_data = rotate_funct(y_data)\n",
    "                else :\n",
    "                    x_data = t(x_data)\n",
    "                    y_data =t(y_data)\n",
    "                \n",
    "        #x_data, y_data = torch.from_numpy(x_data).type(torch.float32), torch.from_numpy(y_data).type(torch.float32)\n",
    "        #x_data = torch.permute(x_data , (1, 2 , 0))\n",
    "        #y_data = torch.permute(y_data , (1 , 2 , 0))\n",
    "        y_data = y_data[: , : , 2] #edit to the last channel\n",
    "        y_data = np.expand_dims( y_data, axis= -1) #(512 512) -> (512 512 1)\n",
    "        return x_data , y_data  #torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "x_shape torch.Size([104, 3, 512, 512])\n",
      "y_shape torch.Size([104, 3, 512, 1])\n",
      "x y mean0 tensor(0.0992) tensor(0.)\n",
      "x y mean1 tensor(0.1579) tensor(0.)\n",
      "x y mean2 tensor(0.1793) tensor(0.)\n",
      "x y std0 tensor(0.1205) tensor(0.)\n",
      "x y std01 tensor(0.1921) tensor(0.)\n",
      "x y std2 tensor(0.2163) tensor(0.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for index in range(5) :\\n    #cv2.imshow(f\"{index}.jpg\" , x[index , : , : , :].detach().cpu().numpy())\\n    #cv2.imshow(f\"{index}.png\" , y[index , : , : , : ].detach().cpu().numpy())\\n    plt.imshow(x[index , : , : , :])\\n    plt.show()\\n    plt.imshow(y[index , : , : , :])\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"mean std calculated\"\"\"\n",
    "#total dataset\n",
    "total_dataset = Total_dataset(total_data_list ,\n",
    "                              total_target_list,\n",
    "                              transform= [T.ToTensor()]\n",
    ")\n",
    "print(len(total_dataset))\n",
    "total_dataloader = DataLoader(total_dataset , batch_size= len(total_dataset) , shuffle= False)\n",
    "#total_dataloader = DataLoader(total_dataset , batch_size= len(total_data_list) , shuffle= False)\n",
    "\n",
    "x , y = next(iter(total_dataloader))\n",
    "print(\"x_shape\", x.shape)\n",
    "print(\"y_shape\" , y.shape)\n",
    "\n",
    "print(\"x y mean0\" ,x[0].mean() , y[0].mean()) #ch1\n",
    "print(\"x y mean1\" ,x[1].mean() , y[1].mean()) #ch2\n",
    "print(\"x y mean2\" ,x[2].mean() , y[2].mean()) #ch3\n",
    "print(\"x y std0\" , x[0].std() , y[0].std()) #ch1\n",
    "print(\"x y std01\" , x[1].std() , y[1].std()) #ch2\n",
    "print(\"x y std2\" , x[2].std() , y[2].std() ) #ch3 \n",
    "\n",
    "#img visualize after to_tensor\n",
    "\"\"\"for index in range(5) :\n",
    "    #cv2.imshow(f\"{index}.jpg\" , x[index , : , : , :].detach().cpu().numpy())\n",
    "    #cv2.imshow(f\"{index}.png\" , y[index , : , : , : ].detach().cpu().numpy())\n",
    "    plt.imshow(x[index , : , : , :])\n",
    "    plt.show()\n",
    "    plt.imshow(y[index , : , : , :])\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"data aug\"\"\"\n",
    "normal = \"T.Normalize([1 , 1 , 1] , [1 , 1 , 1])\"\n",
    "v_flip = \"T.RandomVerticalFlip(p=1)\"\n",
    "h_flip = \"T.RandomHorizontalFlip(p=1)\"\n",
    "r_rotate = \"T.RandomRotation(degrees=(360 , 360))\"\n",
    "#note : rewrite every probability functions in Total_dataset()\n",
    "train_dataset = Total_dataset(train_data_list,\n",
    "                             train_target_list ,\n",
    "                             transform= [T.ToTensor() ,\n",
    "                             normal , \n",
    "                             v_flip , \n",
    "                             h_flip , \n",
    "                             r_rotate,\n",
    "                             T.RandomAutocontrast(p=1) ,\n",
    "                             ])\n",
    "                                             \n",
    "training_dataloader = DataLoader(train_dataset,\n",
    "                                 batch_size=32,\n",
    "                                 shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = Total_dataset(val_img ,\n",
    "                            val_lbl ,\n",
    "                            transform= [ T.ToTensor() , normal , T.RandomAutocontrast(p=1)])\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                                 batch_size=16,\n",
    "                                 shuffle=True)\n",
    "\n",
    "test_dataset = Total_dataset(test_data_list ,\n",
    "                            test_target_list ,\n",
    "                            transform= [ T.ToTensor() , normal , T.RandomAutocontrast(p=1)])\n",
    "\n",
    "testing_dataloader = DataLoader(test_dataset,\n",
    "                                 batch_size=8,\n",
    "                                 shuffle=True)\n",
    "\n",
    "\n",
    "#train_x, train_y = next(iter(training_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class UNET2D(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.CONV1 = nn.Conv2d(3 , 64 , 3 , padding=(1, 1))#conv9\n",
    "        self.CONV1_2 = nn.Conv2d(64 , 64 , 3 , padding=(1, 1))#conv9\n",
    "        self.CONV2 = nn.Conv2d(64 , 128 , 3 , padding=(1, 1))#conv8\n",
    "        self.CONV2_2 = nn.Conv2d(128 , 128 , 3 , padding=(1, 1))#conv8\n",
    "        self.CONV3 = nn.Conv2d(128 , 256 , 3 , padding=(1, 1))#conv7\n",
    "        self.CONV3_2 = nn.Conv2d(256 , 256 , 3 , padding=(1, 1))#conv7\n",
    "        self.CONV4 = nn.Conv2d(256 , 512 , 3  , padding=(1, 1))#conv6\n",
    "        self.CONV4_2 = nn.Conv2d(512 , 512 , 3  , padding=(1, 1))#conv6\n",
    "        self.CONV5 = nn.Conv2d(512 , 1024 , 3 , padding=(1, 1))\n",
    "        self.CONV5_2 = nn.Conv2d(1024 , 1024 , 3 , padding=(1, 1))\n",
    "        self.CONV9_1 = nn.Conv2d(64 , 2 , 3 , padding=(1, 1))\n",
    "        self.CONV9_2 = nn.Conv2d(2 , 1 , 1) #use sigmoid as activation\n",
    "        self.POOL = nn.MaxPool2d(2, 2)\n",
    "        self.DROP = nn.Dropout2d(p = 0.5)\n",
    "    \n",
    "    def forward_test(self , input):\n",
    "        \n",
    "        \"\"\"conv1 = nn.ReLU(self.CONV1(input))\n",
    "        conv1 = nn.ReLU(self.CONV1(conv1))\"\"\"\n",
    "        conv1 = nn.ReLU()(self.CONV1(input))\n",
    "        conv1 = nn.ReLU()(self.CONV1_2 (conv1))\n",
    "        pool1 = self.POOL(conv1)\n",
    "        print(\"pool1\" , pool1.shape)\n",
    "\n",
    "\n",
    "        conv2 = nn.ReLU()(self.CONV2(pool1))\n",
    "        conv2 = nn.ReLU()(self.CONV2_2(conv2))\n",
    "        pool2 = self.POOL(conv2) \n",
    "        print(\"pool2\" , pool2.shape)\n",
    "\n",
    "\n",
    "        conv3 = nn.ReLU()(self.CONV3(pool2))\n",
    "        conv3 = nn.ReLU()(self.CONV3_2(conv3))\n",
    "        pool3 = self.POOL(conv3)\n",
    "        print(\"pool3\" , pool3.shape)\n",
    "\n",
    "        \n",
    "        conv4 = nn.ReLU()(self.CONV4(pool3))\n",
    "        conv4 = nn.ReLU()(self.CONV4_2(conv4))\n",
    "        drop4 = self.DROP(conv4)\n",
    "        pool4 = self.POOL(drop4)\n",
    "        print(\"pool4\" , pool4.shape)\n",
    "\n",
    "\n",
    "        conv5 = nn.ReLU()(self.CONV5(pool4))\n",
    "        conv5 = nn.ReLU()(self.CONV5_2(conv5))\n",
    "        drop5 = self.DROP(conv5)\n",
    "        print(\"drop5\" , drop5.shape)\n",
    "        #############################################\n",
    "        up6 = nn.Conv2d(1024 , 512 , 2 , padding=\"same\")(nn.Upsample(scale_factor=2, mode='nearest')(drop5))\n",
    "        merge6 = torch.cat((drop4 , up6) , dim = 1)\n",
    "        print(\"merge6\" , merge6.shape)\n",
    "        conv6 = nn.Conv2d(1024 , 512 , 3 , padding=\"same\")(merge6)\n",
    "        conv6 = nn.Conv2d(512 , 512 , 3 , padding=\"same\")(conv6)\n",
    "        print(\"conv6\" , conv6.shape)\n",
    "\n",
    "        up7 = nn.Conv2d(512 , 256 , 2 , padding=\"same\")(nn.Upsample(scale_factor=2, mode='nearest')(conv6))\n",
    "        merge7 = torch.cat((conv3 , up7) , dim = 1)\n",
    "        conv7 = nn.Conv2d(512 , 256 , 3 , padding=\"same\")(merge7)\n",
    "        conv7 = nn.Conv2d(256 , 256 , 3 , padding=\"same\")(conv7)\n",
    "\n",
    "        up8 = nn.Conv2d(256 , 128 , 2 , padding=\"same\")(nn.Upsample(scale_factor=2, mode='nearest')(conv7))\n",
    "        merge8 = torch.cat((conv2 , up8) , dim = 1)\n",
    "        conv8 = nn.Conv2d(256 , 128 , 3 , padding=\"same\")(merge8)\n",
    "        conv8 = nn.Conv2d(128 , 128 , 3 , padding=\"same\")(conv8)\n",
    "\n",
    "        up9 = nn.Conv2d(128 , 64 , 2 , padding=\"same\")(nn.Upsample(scale_factor=2, mode='nearest')(conv8))\n",
    "        merge9 = torch.cat((conv1 , up9) , dim = 1)\n",
    "        #merge9 (1, 512, 512, 128)\n",
    "        conv9 = nn.Conv2d(128 , 64 , 3 , padding=\"same\")(merge9)\n",
    "        conv9 = nn.Conv2d(64 , 64 , 3 , padding=\"same\")(conv9)\n",
    "        conv9 = nn.Conv2d(64 , 2 , 3 , padding=\"same\")(conv9)\n",
    "        conv10 = nn.Sigmoid()(nn.Conv2d(2 , 1 , 1 , padding=\"same\")(conv9))\n",
    "        print(\"conv10\" , conv10.shape)\n",
    "    \n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        \"\"\"conv1 = nn.ReLU(self.CONV1(input))\n",
    "        conv1 = nn.ReLU(self.CONV1(conv1))\"\"\"\n",
    "        conv1 = nn.ReLU()(self.CONV1(input))\n",
    "        conv1 = nn.ReLU()(self.CONV1_2 (conv1))\n",
    "        pool1 = self.POOL(conv1)\n",
    "        print(\"pool1\" , pool1.shape)\n",
    "\n",
    "\n",
    "        conv2 = nn.ReLU()(self.CONV2(pool1))\n",
    "        conv2 = nn.ReLU()(self.CONV2_2(conv2))\n",
    "        pool2 = self.POOL(conv2) \n",
    "        print(\"pool2\" , pool2.shape)\n",
    "\n",
    "\n",
    "        conv3 = nn.ReLU()(self.CONV3(pool2))\n",
    "        conv3 = nn.ReLU()(self.CONV3_2(conv3))\n",
    "        pool3 = self.POOL(conv3)\n",
    "        print(\"pool3\" , pool3.shape)\n",
    "\n",
    "        \n",
    "        conv4 = nn.ReLU()(self.CONV4(pool3))\n",
    "        conv4 = nn.ReLU()(self.CONV4_2(conv4))\n",
    "        drop4 = self.DROP(conv4)\n",
    "        pool4 = self.POOL(drop4)\n",
    "        print(\"pool4\" , pool4.shape)\n",
    "\n",
    "\n",
    "        conv5 = nn.ReLU()(self.CONV5(pool4))\n",
    "        conv5 = nn.ReLU()(self.CONV5_2(conv5))\n",
    "        drop5 = self.DROP(conv5)\n",
    "        print(\"drop5\" , drop5.shape)\n",
    "        #############################################\n",
    "        up6 = nn.Conv2d(1024 , 512 , 2 , padding=\"same\")(nn.Upsample(scale_factor=2, mode='nearest')(drop5))\n",
    "        merge6 = torch.cat((drop4 , up6) , dim = 1)\n",
    "        print(\"merge6\" , merge6.shape)\n",
    "        conv6 = nn.Conv2d(1024 , 512 , 3 , padding=\"same\")(merge6)\n",
    "        conv6 = nn.Conv2d(512 , 512 , 3 , padding=\"same\")(conv6)\n",
    "        print(\"conv6\" , conv6.shape)\n",
    "\n",
    "        up7 = nn.Conv2d(512 , 256 , 2 , padding=\"same\")(nn.Upsample(scale_factor=2, mode='nearest')(conv6))\n",
    "        merge7 = torch.cat((conv3 , up7) , dim = 1)\n",
    "        conv7 = nn.Conv2d(512 , 256 , 3 , padding=\"same\")(merge7)\n",
    "        conv7 = nn.Conv2d(256 , 256 , 3 , padding=\"same\")(conv7)\n",
    "\n",
    "        up8 = nn.Conv2d(256 , 128 , 2 , padding=\"same\")(nn.Upsample(scale_factor=2, mode='nearest')(conv7))\n",
    "        merge8 = torch.cat((conv2 , up8) , dim = 1)\n",
    "        conv8 = nn.Conv2d(256 , 128 , 3 , padding=\"same\")(merge8)\n",
    "        conv8 = nn.Conv2d(128 , 128 , 3 , padding=\"same\")(conv8)\n",
    "\n",
    "        up9 = nn.Conv2d(128 , 64 , 2 , padding=\"same\")(nn.Upsample(scale_factor=2, mode='nearest')(conv8))\n",
    "        merge9 = torch.cat((conv1 , up9) , dim = 1)\n",
    "        #merge9 (1, 512, 512, 128)\n",
    "        conv9 = nn.Conv2d(128 , 64 , 3 , padding=\"same\")(merge9)\n",
    "        conv9 = nn.Conv2d(64 , 64 , 3 , padding=\"same\")(conv9)\n",
    "        conv9 = nn.Conv2d(64 , 2 , 3 , padding=\"same\")(conv9)\n",
    "        conv10 = nn.Sigmoid()(nn.Conv2d(2 , 1 , 1 , padding=\"same\")(conv9))\n",
    "        \n",
    "        return conv10\n",
    "\n",
    "\n",
    "unet = UNET2D()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool1 torch.Size([1, 64, 256, 256])\n",
      "pool2 torch.Size([1, 128, 128, 128])\n",
      "pool3 torch.Size([1, 256, 64, 64])\n",
      "pool4 torch.Size([1, 512, 32, 32])\n",
      "drop5 torch.Size([1, 1024, 32, 32])\n",
      "merge6 torch.Size([1, 1024, 64, 64])\n",
      "conv6 torch.Size([1, 512, 64, 64])\n",
      "conv10 torch.Size([1, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test\"\"\"\n",
    "#input torch.Size([32, 3 , 512 , 512])\n",
    "input = torch.randn(1 , 3 , 512 , 512)\n",
    "unet.forward_test(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(unet.parameters() , lr = learning_rate)\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 512, 512])\n",
      "pool1 torch.Size([32, 64, 256, 256])\n",
      "pool2 torch.Size([32, 128, 128, 128])\n",
      "pool3 torch.Size([32, 256, 64, 64])\n",
      "pool4 torch.Size([32, 512, 32, 32])\n",
      "drop5 torch.Size([32, 1024, 32, 32])\n",
      "merge6 torch.Size([32, 1024, 64, 64])\n",
      "conv6 torch.Size([32, 512, 64, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4294967296 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Temp/ipykernel_23580/2907679778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Temp/ipykernel_23580/982018069.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0mconv8\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mup9\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m         \u001b[0mmerge9\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mup9\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;31m#merge9 (1, 512, 512, 128)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign_corners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor)\u001b[0m\n\u001b[0;32m   3710\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsample_nearest1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3711\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nearest\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3712\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsample_nearest2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3713\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nearest\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3714\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsample_nearest3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4294967296 bytes."
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(training_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data #batched\n",
    "        print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = unet(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 50))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b562ed37188020c8a8c07b69b9eae1a2662f56daf78cc992f9676fd3c0f765c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('2dunet': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

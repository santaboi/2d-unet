{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import numpy as np\n","import pandas as pd\n","import scipy.io\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import gc\n","gc.collect()\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","import os\n","print(os.listdir(\"../input\"))\n","\n","# Any results you write to the current directory are saved as output."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["# https://www.kaggle.com/pierrenicolaspiquin/oct-segmentation/data\n","# Settings\n","input_path = os.path.join('..', 'input', '2015_boe_chiu', '2015_BOE_Chiu')\n","subject_path = [os.path.join(input_path, 'Subject_0{}.mat'.format(i)) for i in range(1, 10)] + [os.path.join(input_path, 'Subject_10.mat')]\n","\n","data_indexes = [10, 15, 20, 25, 28, 30, 32, 35, 40, 45, 50]\n","\n","width = 284\n","height = 284\n","width_out = 196\n","height_out = 196"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6ef1ef489b94a75842b314394096c36989952fb3","trusted":true},"outputs":[],"source":["mat = scipy.io.loadmat(subject_path[0])\n","img_tensor = mat['images']\n","manual_fluid_tensor_1 = mat['manualFluid1']\n","\n","img_array = np.transpose(img_tensor, (2, 0, 1))\n","manual_fluid_array = np.transpose(manual_fluid_tensor_1, (2, 0, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"dba8cf88263f95215390080b2a2900ad2c75c68a","trusted":true},"outputs":[],"source":["plt.imshow(img_array[25])"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"1e79ecb04784ee9c9bfdbb409532e52198d7b129","trusted":true},"outputs":[],"source":["plt.imshow(manual_fluid_array[25])"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"3a4cda6ed011af43db0a530705c126b1bf17fb31","trusted":true},"outputs":[],"source":["def thresh(x):\n","    if x == 0:\n","        return 0\n","    else:\n","        return 1\n","\n","thresh = np.vectorize(thresh, otypes=[np.float])\n","\n","def create_dataset(paths):\n","    x = []\n","    y = []\n","    \n","    for path in tqdm(paths):\n","        mat = scipy.io.loadmat(path)\n","        img_tensor = mat['images']\n","        fluid_tensor = mat['manualFluid1']\n","        \n","        img_array = np.transpose(img_tensor, (2, 0 ,1)) / 255\n","        img_array = resize(img_array, (img_array.shape[0], width, height))\n","        fluid_array = np.transpose(fluid_tensor, (2, 0 ,1))\n","        fluid_array = thresh(fluid_array)\n","        fluid_array  = resize(fluid_array, (fluid_array .shape[0], width_out, height_out))\n","\n","        for idx in data_indexes:\n","            x += [np.expand_dims(img_array[idx], 0)]\n","            y += [np.expand_dims(fluid_array[idx], 0)]\n","    return np.array(x), np.array(y)\n","\n","x_train, y_train = create_dataset(subject_path[:9])\n","x_val, y_val = create_dataset(subject_path[9:])"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"d0002329b2e686747c1dd58074bd037623336613","trusted":true},"outputs":[],"source":["x_train.shape, y_train.shape, x_val.shape, y_val.shape"]},{"cell_type":"markdown","metadata":{"_uuid":"a2ff987911b74df02acf877308b0da39b0a71d07"},"source":["## Unet"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8c8eddd54c9dd224ec8ea4709cc917750417334e","trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from tqdm import trange\n","from time import sleep\n","use_gpu = torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"df9a4eb05e80d6753af80b30792ee1835d431eab","trusted":true},"outputs":[],"source":["batch_size = 9\n","epochs = 1000\n","epoch_lapse = 50\n","threshold = 0.5\n","sample_size = None"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"9268579ea9ef2cb380cc62ff32869485002df3fe","trusted":true},"outputs":[],"source":["class UNet(nn.Module):\n","    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels),\n","                    torch.nn.ReLU(),\n","                    torch.nn.BatchNorm2d(out_channels),\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels),\n","                    torch.nn.ReLU(),\n","                    torch.nn.BatchNorm2d(out_channels),\n","                )\n","        return block\n","    \n","    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","            block = torch.nn.Sequential(\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n","                    torch.nn.ReLU(),\n","                    torch.nn.BatchNorm2d(mid_channel),\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n","                    torch.nn.ReLU(),\n","                    torch.nn.BatchNorm2d(mid_channel),\n","                    torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n","                    )\n","            return  block\n","    \n","    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","            block = torch.nn.Sequential(\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n","                    torch.nn.ReLU(),\n","                    torch.nn.BatchNorm2d(mid_channel),\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n","                    torch.nn.ReLU(),\n","                    torch.nn.BatchNorm2d(mid_channel),\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n","                    torch.nn.ReLU(),\n","                    torch.nn.BatchNorm2d(out_channels),\n","                    )\n","            return  block\n","    \n","    def __init__(self, in_channel, out_channel):\n","        super(UNet, self).__init__()\n","        #Encode\n","        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n","        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n","        self.conv_encode2 = self.contracting_block(64, 128)\n","        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n","        self.conv_encode3 = self.contracting_block(128, 256)\n","        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n","        # Bottleneck\n","        self.bottleneck = torch.nn.Sequential(\n","                            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512),\n","                            torch.nn.ReLU(),\n","                            torch.nn.BatchNorm2d(512),\n","                            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512),\n","                            torch.nn.ReLU(),\n","                            torch.nn.BatchNorm2d(512),\n","                            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n","                            )\n","        # Decode\n","        self.conv_decode3 = self.expansive_block(512, 256, 128)\n","        self.conv_decode2 = self.expansive_block(256, 128, 64)\n","        self.final_layer = self.final_block(128, 64, out_channel)\n","        \n","    def crop_and_concat(self, upsampled, bypass, crop=False):\n","        if crop:\n","            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n","            bypass = F.pad(bypass, (-c, -c, -c, -c))\n","        return torch.cat((upsampled, bypass), 1)\n","    \n","    def forward(self, x):\n","        # Encode\n","        encode_block1 = self.conv_encode1(x)\n","        encode_pool1 = self.conv_maxpool1(encode_block1)\n","        encode_block2 = self.conv_encode2(encode_pool1)\n","        encode_pool2 = self.conv_maxpool2(encode_block2)\n","        encode_block3 = self.conv_encode3(encode_pool2)\n","        encode_pool3 = self.conv_maxpool3(encode_block3)\n","        # Bottleneck\n","        bottleneck1 = self.bottleneck(encode_pool3)\n","        # Decode\n","        ##print(x.shape, encode_block1.shape, encode_block2.shape, encode_block3.shape, bottleneck1.shape)\n","        ##print('Decode Block 3')\n","        ##print(bottleneck1.shape, encode_block3.shape)\n","        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True)\n","        ##print(decode_block3.shape)\n","        ##print('Decode Block 2')\n","        cat_layer2 = self.conv_decode3(decode_block3)\n","        ##print(cat_layer2.shape, encode_block2.shape)\n","        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n","        cat_layer1 = self.conv_decode2(decode_block2)\n","        ##print(cat_layer1.shape, encode_block1.shape)\n","        ##print('Final Layer')\n","        ##print(cat_layer1.shape, encode_block1.shape)\n","        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=True)\n","        ##print(decode_block1.shape)\n","        final_layer = self.final_layer(decode_block1)\n","        ##print(final_layer.shape)\n","        return  final_layer\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"147d92a2e447e39328ffc31a6935112322efcbb6","trusted":true},"outputs":[],"source":["def train_step(inputs, labels, optimizer, criterion):\n","    optimizer.zero_grad()\n","    # forward + backward + optimize\n","    outputs = unet(inputs)\n","    # outputs.shape =(batch_size, n_classes, img_cols, img_rows) \n","    outputs = outputs.permute(0, 2, 3, 1)\n","    # outputs.shape =(batch_size, img_cols, img_rows, n_classes) \n","    outputs = outputs.resize(batch_size*width_out*height_out, 2)\n","    labels = labels.resize(batch_size*width_out*height_out)\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e2127d9718e15c2ab0f0de1affc5979df953a06d","trusted":true},"outputs":[],"source":["learning_rate = 0.01\n","unet = UNet(in_channel=1,out_channel=2)\n","if use_gpu:\n","    unet = unet.cuda()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(unet.parameters(), lr = 0.01, momentum=0.99)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4106bb0c66aac010c730d5ca3559291e5cbd9c39","trusted":true},"outputs":[],"source":["def get_val_loss(x_val, y_val):\n","    x_val = torch.from_numpy(x_val).float()\n","    y_val = torch.from_numpy(y_val).long()\n","    if use_gpu:\n","        x_val = x_val.cuda()\n","        y_val = y_val.cuda()\n","    m = x_val.shape[0]\n","    outputs = unet(x_val)\n","    # outputs.shape =(batch_size, n_classes, img_cols, img_rows) \n","    outputs = outputs.permute(0, 2, 3, 1)\n","    # outputs.shape =(batch_size, img_cols, img_rows, n_classes) \n","    outputs = outputs.resize(m*width_out*height_out, 2)\n","    labels = y_val.resize(m*width_out*height_out)\n","    loss = F.cross_entropy(outputs, labels)\n","    return loss.data"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"cd90cb9ba80336306fab66570262ecc4edf3ee31","trusted":true},"outputs":[],"source":["epoch_iter = np.ceil(x_train.shape[0] / batch_size).astype(int)\n","t = trange(epochs, leave=True)\n","for _ in t:\n","    total_loss = 0\n","    for i in range(epoch_iter):\n","        batch_train_x = torch.from_numpy(x_train[i * batch_size : (i + 1) * batch_size]).float()\n","        batch_train_y = torch.from_numpy(y_train[i * batch_size : (i + 1) * batch_size]).long()\n","        if use_gpu:\n","            batch_train_x = batch_train_x.cuda()\n","            batch_train_y = batch_train_y.cuda()\n","        batch_loss = train_step(batch_train_x , batch_train_y, optimizer, criterion)\n","        total_loss += batch_loss\n","    if (_+1) % epoch_lapse == 0:\n","        val_loss = get_val_loss(x_val, y_val)\n","        print(f\"Total loss in epoch {_+1} : {total_loss / epoch_iter} and validation loss : {val_loss}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"1f3df518a3873fcca42242a233371291635daf35","trusted":true},"outputs":[],"source":["gc.collect()"]},{"cell_type":"code","execution_count":85,"metadata":{"_uuid":"7c3c1a18ba457f891c4bc77d48d70624b79e4ed6","trusted":true},"outputs":[],"source":["def plot_examples(datax, datay, num_examples=3):\n","    fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(18,4*num_examples))\n","    m = datax.shape[0]\n","    for row_num in range(num_examples):\n","        image_indx = np.random.randint(m)\n","        image_arr = unet(torch.from_numpy(datax[image_indx:image_indx+1]).float().cuda()).squeeze(0).detach().cpu().numpy()\n","        ax[row_num][0].imshow(np.transpose(datax[image_indx], (1,2,0))[:,:,0])\n","        ax[row_num][0].set_title(\"Orignal Image\")\n","        ax[row_num][1].imshow(np.transpose(image_arr, (1,2,0))[:,:,0])\n","        ax[row_num][1].set_title(\"Segmented Image\")\n","        ax[row_num][2].imshow(image_arr.argmax(0))\n","        ax[row_num][2].set_title(\"Segmented Image localization\")\n","        ax[row_num][3].imshow(np.transpose(datay[image_indx], (1,2,0))[:,:,0])\n","        ax[row_num][3].set_title(\"Target image\")\n","    plt.show()"]},{"cell_type":"code","execution_count":86,"metadata":{"_uuid":"c913f6a02fd0ea1e311200be281bccb874da4b3c","trusted":true},"outputs":[],"source":["plot_examples(x_train, y_train)"]},{"cell_type":"code","execution_count":87,"metadata":{"_uuid":"70400c721a19e410e2c3ed2b2ec3977ebd2f7e35","trusted":true},"outputs":[],"source":["plot_examples(x_val, y_val)"]},{"cell_type":"code","execution_count":76,"metadata":{"_uuid":"2d78a738b99d282c10b69725f8f2c6e2f05585b9","trusted":true},"outputs":[],"source":["torch.save(unet.state_dict(), 'unet.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b2185b4c4854ba1189ec6bdd38ac5436f189662c","trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}

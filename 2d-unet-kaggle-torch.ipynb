{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport skimage.transform as trans\nimport skimage.io as io\n\nimport numpy as np \nimport os\nimport glob\n\nimport tensorflow as tf\nseed_value= 666\nos.environ['PYTHONHASHSEED']=str(seed_value)\nnp.random.seed(seed_value)\ntf.random.set_seed(seed_value)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T10:59:49.592537Z","iopub.execute_input":"2022-01-02T10:59:49.593181Z","iopub.status.idle":"2022-01-02T10:59:54.714327Z","shell.execute_reply.started":"2022-01-02T10:59:49.593145Z","shell.execute_reply":"2022-01-02T10:59:54.713556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Folder List","metadata":{}},{"cell_type":"code","source":"#cfg file content\n\n#whole brain\nnon_T1C_data = \"../input/chimei-tumor-segmentation/PSPF_voc_data/non_PR/T1c/JPEGImages\"  \nPR_T1C_data = \"../input/chimei-tumor-segmentation/PSPF_voc_data/PR/T1c/JPEGImages\" \n\nnon_T1_data = \"../input/chimei-tumor-segmentation/PSPF_voc_data/non_PR/T1/JPEGImages\" \nPR_T1_data = \"../input/chimei-tumor-segmentation/PSPF_voc_data/PR/T1/JPEGImages\" \n\nnon_Flair_data = \"../input/chimei-tumor-segmentation/PSPF_voc_data/non_PR/Flair/JPEGImages\" \nPR_Flair_data = \"../input/chimei-tumor-segmentation/PSPF_voc_data/PR/Flair/JPEGImages\" \n\nnon_T2_data = \"../input/chimei-tumor-segmentation/PSPF_voc_data/non_PR/T2/JPEGImages\" \nPR_T2_data = \"../input/chimei-tumor-segmentation/PSPF_voc_data/PR/T2/JPEGImages\" \n#mask (ground truth)\nnon_T1C_target = \"../input/chimei-tumor-segmentation/PSPF_voc_data/non_PR/T1c/SegmentationClassPNG\"\nPR_T1C_target = \"../input/chimei-tumor-segmentation/PSPF_voc_data/PR/T1c/SegmentationClassPNG\"\n\nnon_T1_target = \"../input/chimei-tumor-segmentation/PSPF_voc_data/non_PR/T1/SegmentationClassPNG\"\nPR_T1_target = \"../input/chimei-tumor-segmentation/PSPF_voc_data/PR/T1/SegmentationClassPNG\"\n\nnon_Flair_target = \"../input/chimei-tumor-segmentation/PSPF_voc_data/non_PR/Flair/SegmentationClassPNG\" \nPR_Flair_target = \"../input/chimei-tumor-segmentation/PSPF_voc_data/PR/Flair/SegmentationClassPNG\"\n\nnon_T2_target = \"../input/chimei-tumor-segmentation/PSPF_voc_data/non_PR/T2/SegmentationClassPNG\" \nPR_T2_target = \"../input/chimei-tumor-segmentation/PSPF_voc_data/PR/T2/SegmentationClassPNG\"","metadata":{"execution":{"iopub.status.busy":"2022-01-02T10:59:54.715933Z","iopub.execute_input":"2022-01-02T10:59:54.719138Z","iopub.status.idle":"2022-01-02T10:59:54.725415Z","shell.execute_reply.started":"2022-01-02T10:59:54.719108Z","shell.execute_reply":"2022-01-02T10:59:54.724309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"load data\"\"\"\n#patients in data_folcder is cinsistent with traget_folder\nnon_name_set = set()\nPR_name_set = set()\nname_set = set()\ntotal_data_path = [non_T1C_data , non_T1_data , non_Flair_data , non_T2_data , PR_T1C_data , PR_T1_data , PR_Flair_data  , PR_T2_data]\ncount1 = 0\nfor folder_name in total_data_path :\n    for name in os.listdir(folder_name) :\n        name = name.strip('.jpg').strip('.json')\n        if name == 'ipynb_checkpoint' :\n            continue\n        name_set.add(name)\n        if count1 <= 3 :\n            non_name_set.add(name)\n        else :\n            PR_name_set.add(name)\n    count1 += 1\n#print(name_set)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T10:59:54.726736Z","iopub.execute_input":"2022-01-02T10:59:54.727475Z","iopub.status.idle":"2022-01-02T10:59:54.903528Z","shell.execute_reply.started":"2022-01-02T10:59:54.727417Z","shell.execute_reply":"2022-01-02T10:59:54.902758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_data_list = []\ntotal_target_list =[] \nfor non_name , pr_name in zip(non_name_set , PR_name_set) :\n    non_name1 = non_name + \".jpg\"\n    non_name2 = non_name + \".png\"\n    pr_name1 = pr_name + \".jpg\"\n    pr_name2 = pr_name + \".png\"\n    total_data_list.append(os.path.join(non_T1C_data , non_name1))\n    total_data_list.append(os.path.join(non_T1_data , non_name1))\n    total_data_list.append(os.path.join(non_Flair_data , non_name1))\n    total_data_list.append(os.path.join(non_T2_data , non_name1))\n    total_target_list.append(os.path.join(non_T1C_target , non_name2))\n    total_target_list.append(os.path.join(non_T1_target , non_name2))\n    total_target_list.append(os.path.join(non_Flair_target , non_name2))\n    total_target_list.append(os.path.join(non_T2_target , non_name2))\n    \n    total_data_list.append(os.path.join(PR_T1C_data , pr_name1))\n    total_data_list.append(os.path.join(PR_T1_data , pr_name1))\n    total_data_list.append(os.path.join(PR_Flair_data , pr_name1))\n    total_data_list.append(os.path.join(PR_T2_data , pr_name1))\n    total_target_list.append(os.path.join(PR_T1C_target , pr_name2))\n    total_target_list.append(os.path.join(PR_T1_target , pr_name2))\n    total_target_list.append(os.path.join(PR_Flair_target , pr_name2))\n    total_target_list.append(os.path.join(PR_T2_target , pr_name2)) ","metadata":{"execution":{"iopub.status.busy":"2022-01-02T10:59:54.905404Z","iopub.execute_input":"2022-01-02T10:59:54.905648Z","iopub.status.idle":"2022-01-02T10:59:54.920378Z","shell.execute_reply.started":"2022-01-02T10:59:54.905616Z","shell.execute_reply":"2022-01-02T10:59:54.919549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_list = total_data_list[0 : int(len(total_data_list)*0.9)] #90%data\ntrain_target_list =  total_target_list[0 : int(len(total_target_list)*0.9) ] #90%target\n\ntest_data_list = total_data_list[int(len(total_data_list)*0.9) : len(total_data_list)] #90%data\ntest_target_list = total_target_list[int(len(total_target_list)*0.9) : len(total_target_list)] #90%target\n\nval_img = train_data_list[0 : int(0.2* len(train_data_list))]\nval_lbl = train_target_list[0 : int(0.2* len(train_target_list))]\ntrain_data_list = train_data_list[int(0.2* len(train_data_list)) : ]\ntrain_target_list = train_target_list[int(0.2* len(train_target_list)) : ]\nprint(len(train_data_list))\nprint(len(train_target_list))\nprint(len(test_data_list))\nprint(len(test_target_list))\nprint(len(val_img))\nprint(len(val_lbl))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T10:59:54.923433Z","iopub.execute_input":"2022-01-02T10:59:54.923633Z","iopub.status.idle":"2022-01-02T10:59:54.93491Z","shell.execute_reply.started":"2022-01-02T10:59:54.923604Z","shell.execute_reply":"2022-01-02T10:59:54.933903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocess","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import DataLoader , Dataset \n\nimport matplotlib.pyplot as plt\nimport cv2\nimport torchvision.transforms as T \nfrom torchvision.transforms.functional import hflip , vflip\nimport torch\n\nclass Total_dataset(Dataset):\n    def __init__(self, inputs: list, targets: list, transform=None) -> None:\n        super().__init__()\n        self.inputs = inputs\n        self.targets = targets\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.inputs)\n    def __getitem__(self , index : int  , transform = None):\n        #是否有辦法用path + file name取用data\n        input_img = self.inputs[index]\n        target_img = self.targets[index]\n        \n        x_data , y_data = cv2.imread(input_img) , cv2.imread(target_img)\n        \n        #print(x_data.shape)\n        #print(y_data.shape)\n        \n        \n        #resize\n        if x_data.shape != (512 , 512 , 3) :\n            x_data = cv2.resize(x_data , (512 , 512))\n        if y_data.shape != (512 , 512 , 3) :\n            y_data = cv2.resize(y_data , (512 ,512))\n\n        # turn to torch (typecasting)\n\n        #data augmentaion if true\n        if self.transform != None : \n            #x_data , y_data = self.transform(x_data , y_data)\n            for t in self.transform :\n                if t == \"T.Normalize([1 , 1 , 1] , [1 , 1 , 1])\" :\n                    \"\"\"\n                    x y mean0 tensor(0.2302) tensor(0.0111)\n                    x y mean1 tensor(0.1842) tensor(0.0111)\n                    x y mean2 tensor(0.1870) tensor(0.0111)\n                    x y std0 tensor(0.2334) tensor(0.0737)\n                    x y std01 tensor(0.1999) tensor(0.0737)\n                    x y std2 tensor(0.1987) tensor(0.0737)\n                    \"\"\"\n                    #normalized with whole dataset mean and std (not batchwise)\n                    img_normalize = T.Normalize([0.2302 , 0.1842 , 0.1870] , [0.2334 , 0.1999 , 0.1987])\n                    x_data = img_normalize(x_data)\n                    label_normalize = T.Normalize([0.0111 , 0.0111 , 0.0111 ] , [0.0737 , 0.0737 , 0.0737]) \n                    y_data = label_normalize(y_data)\n                elif t == \"T.RandomHorizontalFlip(p=1)\" :\n                    if torch.rand(1)< 0.5 :\n                        x_data = hflip(x_data)\n                        y_data = hflip(y_data)\n                elif t == \"T.RandomVerticalFlip(p=1)\" :\n                    if torch.rand(1)< 0.5 :\n                        x_data = vflip(x_data)\n                        y_data = vflip(y_data)\n                        \n\n                elif t == \"T.RandomRotation(degrees=(360 , 360))\" : \n                    if torch.rand(1)< 0.5 :\n                        angle = int(torch.rand(1)*360)\n                        rotate_funct = T.RandomRotation(degrees=(angle, angle))\n                        x_data = rotate_funct(x_data)\n                        y_data = rotate_funct(y_data)\n                else :\n                    x_data = t(x_data)\n                    y_data =t(y_data)\n                \n        #x_data, y_data = torch.from_numpy(x_data).type(torch.float32), torch.from_numpy(y_data).type(torch.float32)\n        #x_data = torch.permute(x_data , (1, 2 , 0))\n        #y_data = torch.permute(y_data , (1 , 2 , 0))\n        y_data = y_data[2, : , :] #edit to the last channel\n        y_data = np.expand_dims( y_data, axis= 0) #(512 512) -> (512 512 1)\n        return x_data , y_data  #torch","metadata":{"execution":{"iopub.status.busy":"2022-01-02T10:59:54.936527Z","iopub.execute_input":"2022-01-02T10:59:54.937442Z","iopub.status.idle":"2022-01-02T10:59:56.686062Z","shell.execute_reply.started":"2022-01-02T10:59:54.937401Z","shell.execute_reply":"2022-01-02T10:59:56.68533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"mean std calculated\"\"\"\n#total dataset\ntotal_dataset = Total_dataset(total_data_list ,\n                              total_target_list,\n                              transform= [T.ToTensor()]\n)\nprint(len(total_dataset))\ntotal_dataloader = DataLoader(total_dataset , batch_size= len(total_dataset) , shuffle= False)\n#total_dataloader = DataLoader(total_dataset , batch_size= len(total_data_list) , shuffle= False)\n\nx , y = next(iter(total_dataloader))\nprint(\"x_shape\", x.shape)\nprint(\"y_shape\" , y.shape)\n\nprint(\"x y mean0\" ,x[0].mean() , y[0].mean()) #ch1\nprint(\"x y mean1\" ,x[1].mean() , y[1].mean()) #ch2\nprint(\"x y mean2\" ,x[2].mean() , y[2].mean()) #ch3\nprint(\"x y std0\" , x[0].std() , y[0].std()) #ch1\nprint(\"x y std01\" , x[1].std() , y[1].std()) #ch2\nprint(\"x y std2\" , x[2].std() , y[2].std() ) #ch3 \n\n#img visualize after to_tensor\n\"\"\"for index in range(5) :\n    #cv2.imshow(f\"{index}.jpg\" , x[index , : , : , :].detach().cpu().numpy())\n    #cv2.imshow(f\"{index}.png\" , y[index , : , : , : ].detach().cpu().numpy())\n    plt.imshow(x[index , : , : , :])\n    plt.show()\n    plt.imshow(y[index , : , : , :])\n    plt.show()\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-01-02T10:59:56.687412Z","iopub.execute_input":"2022-01-02T10:59:56.687673Z","iopub.status.idle":"2022-01-02T10:59:59.847823Z","shell.execute_reply.started":"2022-01-02T10:59:56.68764Z","shell.execute_reply":"2022-01-02T10:59:59.847045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"data aug\"\"\"\nnormal = \"T.Normalize([1 , 1 , 1] , [1 , 1 , 1])\"\nv_flip = \"T.RandomVerticalFlip(p=1)\"\nh_flip = \"T.RandomHorizontalFlip(p=1)\"\nr_rotate = \"T.RandomRotation(degrees=(360 , 360))\"\n#note : rewrite every probability functions in Total_dataset()\ntrain_dataset = Total_dataset(train_data_list,\n                             train_target_list ,\n                             transform= [T.ToTensor() ,\n                             normal , \n                             v_flip , \n                             h_flip , \n                             r_rotate,\n                             #T.RandomAutocontrast(p=1) ,\n                             ])\n                                             \ntraining_dataloader = DataLoader(train_dataset,\n                                 batch_size=8,\n                                 shuffle=True)\n\n\nval_dataset = Total_dataset(val_img ,\n                            val_lbl ,\n                            transform= [ T.ToTensor() , normal , \n                                       # T.RandomAutocontrast(p=1)\n                                       ])\n\nval_dataloader = DataLoader(val_dataset,\n                                 batch_size=4,\n                                 shuffle=True)\n\n#, T.RandomAutocontrast(p=1)\ntest_dataset = Total_dataset(test_data_list ,\n                            test_target_list ,\n                            transform= [ T.ToTensor() , normal])\n\ntesting_dataloader = DataLoader(test_dataset,\n                                 batch_size=1,\n                                 shuffle=True)\n\n\n#train_x, train_y = next(iter(training_dataloader))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T11:30:46.094556Z","iopub.execute_input":"2022-01-02T11:30:46.09483Z","iopub.status.idle":"2022-01-02T11:30:46.103655Z","shell.execute_reply.started":"2022-01-02T11:30:46.0948Z","shell.execute_reply":"2022-01-02T11:30:46.101345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.functional as F\nimport torch\n\n\nclass UNET2D(torch.nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.CONV1 = nn.Conv2d(3 , 64 , 3 , padding=(1, 1))#conv9\n        self.CONV1_2 = nn.Conv2d(64 , 64 , 3 , padding=(1, 1))#conv9\n        self.CONV2 = nn.Conv2d(64 , 128 , 3 , padding=(1, 1))#conv8\n        self.CONV2_2 = nn.Conv2d(128 , 128 , 3 , padding=(1, 1))#conv8\n        self.CONV3 = nn.Conv2d(128 , 256 , 3 , padding=(1, 1))#conv7\n        self.CONV3_2 = nn.Conv2d(256 , 256 , 3 , padding=(1, 1))#conv7\n        self.CONV4 = nn.Conv2d(256 , 512 , 3  , padding=(1, 1))#conv6\n        self.CONV4_2 = nn.Conv2d(512 , 512 , 3  , padding=(1, 1))#conv6\n        self.CONV5 = nn.Conv2d(512 , 1024 , 3 , padding=(1, 1))\n        self.CONV5_2 = nn.Conv2d(1024 , 1024 , 3 , padding=(1, 1))\n        self.CONV9_1 = nn.Conv2d(64 , 2 , 3 , padding=(1, 1))\n        self.CONV9_2 = nn.Conv2d(2 , 1 , 1) #use sigmoid as activation\n        self.POOL = nn.MaxPool2d(2, 2)\n        self.DROP = nn.Dropout2d(p = 0.5)\n        self.UP = nn.Upsample(scale_factor=2, mode='nearest')\n        self.CONV5R = nn.Conv2d(1024 , 512 , 2 , padding=\"same\")\n        self.CONV5R_1 = nn.Conv2d(1024 , 512 , 3 , padding=\"same\")\n        self.CONV5R_2 = nn.Conv2d(512 , 512 , 3 , padding=\"same\")\n        self.CONV2R = nn.Conv2d(512 , 256 , 2 , padding=\"same\")\n        self.CONV2R_1 = nn.Conv2d(512 , 256 , 3 , padding=\"same\")\n        self.CONV2R_2 = nn.Conv2d(256 , 256 , 3 , padding=\"same\")\n        self.CONV3R = nn.Conv2d(256 , 128 , 2 , padding=\"same\")\n        self.CONV3R_1 = nn.Conv2d(256 , 128 , 3 , padding=\"same\")\n        self.CONV3R_2 = nn.Conv2d(128 , 128 , 3 , padding=\"same\")\n        self.CONV_last1 = nn.Conv2d(128 , 64 , 2 , padding=\"same\")\n        self.CONV_last2 = nn.Conv2d(128 , 64 , 3 , padding=\"same\")\n        self.CONV_last3 = nn.Conv2d(64 , 64 , 3 , padding=\"same\")\n        self.CONV_last4 = nn.Conv2d(64 , 2 , 3 , padding=\"same\")\n        self.CONV_last5 = nn.Conv2d(2 , 1 , 1 , padding=\"same\")\n        self.SIGM = nn.Sigmoid()\n    \n\n    def forward(self, input):\n        \n        \"\"\"conv1 = nn.ReLU(self.CONV1(input))\n        conv1 = nn.ReLU(self.CONV1(conv1))\"\"\"\n        conv1 = nn.ReLU()(self.CONV1(input))\n        conv1 = nn.ReLU()(self.CONV1_2 (conv1))\n        pool1 = self.POOL(conv1)\n        #print(\"pool1\" , pool1.shape)\n\n\n        conv2 = nn.ReLU()(self.CONV2(pool1))\n        conv2 = nn.ReLU()(self.CONV2_2(conv2))\n        pool2 = self.POOL(conv2) \n        #print(\"pool2\" , pool2.shape)\n\n\n        conv3 = nn.ReLU()(self.CONV3(pool2))\n        conv3 = nn.ReLU()(self.CONV3_2(conv3))\n        pool3 = self.POOL(conv3)\n        #print(\"pool3\" , pool3.shape)\n\n        \n        conv4 = nn.ReLU()(self.CONV4(pool3))\n        conv4 = nn.ReLU()(self.CONV4_2(conv4))\n        drop4 = self.DROP(conv4)\n        pool4 = self.POOL(drop4)\n        #print(\"pool4\" , pool4.shape)\n\n\n        conv5 = nn.ReLU()(self.CONV5(pool4))\n        conv5 = nn.ReLU()(self.CONV5_2(conv5))\n        drop5 = self.DROP(conv5)\n        #print(\"drop5\" , drop5.shape)\n        #############################################\n        up6 = self.CONV5R(self.UP(drop5))\n        merge6 = torch.cat((drop4 , up6) , dim = 1)\n        #print(\"merge6\" , merge6.shape)\n        conv6 = self.CONV5R_1(merge6)\n        conv6 = self.CONV5R_2(conv6)\n        #print(\"conv6\" , conv6.shape)\n\n        up7 = self.CONV2R(self.UP(conv6))\n        merge7 = torch.cat((conv3 , up7) , dim = 1)\n        conv7 = self.CONV2R_1(merge7)\n        conv7 = self.CONV2R_2(conv7)\n\n        up8 = self.CONV3R(self.UP(conv7))\n        merge8 = torch.cat((conv2 , up8) , dim = 1)\n        conv8 = self.CONV3R_1(merge8)\n        conv8 = self.CONV3R_2(conv8)\n\n        up9 = self.CONV_last1(self.UP(conv8))\n        merge9 = torch.cat((conv1 , up9) , dim = 1)\n        #merge9 (1, 512, 512, 128)\n        conv9 = self.CONV_last2(merge9)\n        conv9 = self.CONV_last3(conv9)\n        conv9 = self.CONV_last4(conv9)\n        temp9 = self.CONV_last5(conv9)\n        conv10 = self.SIGM(temp9)\n        \n        return conv10\n\n\nunet = UNET2D()\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device1)\n#in-place\nunet.to(device1)\n#unet.cuda()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T10:59:59.859305Z","iopub.execute_input":"2022-01-02T10:59:59.860057Z","iopub.status.idle":"2022-01-02T11:00:03.846783Z","shell.execute_reply.started":"2022-01-02T10:59:59.859953Z","shell.execute_reply":"2022-01-02T11:00:03.84613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"test\"\"\"\n#input torch.Size([32, 3 , 512 , 512])\n\"\"\"\ninput = torch.randn(1 , 3 , 512 , 512)\nunet.forward_test(input)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-01-02T11:00:03.849254Z","iopub.execute_input":"2022-01-02T11:00:03.849584Z","iopub.status.idle":"2022-01-02T11:00:03.854345Z","shell.execute_reply.started":"2022-01-02T11:00:03.849547Z","shell.execute_reply":"2022-01-02T11:00:03.853524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (Training) Loss function and optimizer","metadata":{}},{"cell_type":"code","source":"learning_rate = 1e-4\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T11:00:03.855776Z","iopub.execute_input":"2022-01-02T11:00:03.856228Z","iopub.status.idle":"2022-01-02T11:00:03.862746Z","shell.execute_reply.started":"2022-01-02T11:00:03.856195Z","shell.execute_reply":"2022-01-02T11:00:03.861886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### taining two ############\nimport torch.optim as optim\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = optim.SGD(unet.parameters(), lr = 0.01, momentum=0.99)\nfor epoch in range(30):  # loop over the dataset multiple times\n    running_loss = 0.0\n    for i, data in enumerate(training_dataloader, 0) :\n        # Resizing the outputs and label to caculate pixel wise softmax loss\n        optimizer.zero_grad() \n        inputs, labels = data #batched\n        inputs = inputs.to(device1)\n        labels = labels.to(device1)\n        \n        outputs = unet(inputs)\n        \n        outputs = outputs.to(device1)\n        print(outputs.shape)\n        break\n        \"\"\"loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        # print statistics\n        running_loss += loss.item()\n        if i % 10 == 9:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 10))\n            running_loss = 0.0\"\"\"\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2022-01-02T12:04:34.290842Z","iopub.execute_input":"2022-01-02T12:04:34.291415Z","iopub.status.idle":"2022-01-02T12:04:34.516229Z","shell.execute_reply.started":"2022-01-02T12:04:34.29138Z","shell.execute_reply":"2022-01-02T12:04:34.515158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### taining one ############\nimport torch.optim as optim\noptimizer = optim.Adam(unet.parameters() , lr = learning_rate)\nloss_function = nn.BCELoss()\n\nfor epoch in range(3):  # loop over the dataset multiple times\n    running_loss = 0.0\n    for i, data in enumerate(training_dataloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data #batched\n        inputs = inputs.to(device1)\n        labels = labels.to(device1)\n        #print(inputs.shape , labels.shape)\n        #print(inputs.shape)\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = unet(inputs)\n        outputs = outputs.to(device1)\n        loss = loss_function(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 10 == 9:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 10))\n            running_loss = 0.0\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2022-01-02T11:58:37.744491Z","iopub.execute_input":"2022-01-02T11:58:37.74475Z","iopub.status.idle":"2022-01-02T11:58:41.770261Z","shell.execute_reply.started":"2022-01-02T11:58:37.744722Z","shell.execute_reply":"2022-01-02T11:58:41.769484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"clean ram\"\"\"\nimport os\nimport gc\nimport psutil\nimport pandas as pd\nimport numpy  as np \n\n\nprocess = psutil.Process(os.getpid())\nprint('start', process.memory_info().rss)\n\nmtx  = np.zeros((100000000, 1)).astype('int')\ndf   = pd.DataFrame(mtx)\n\nprint('df created', process.memory_info().rss)\n\ndel df;  gc.collect()\n\nprint('df deleted', process.memory_info().rss)\n\ndel mtx;  gc.collect()\n\nprint('mtx deleted', process.memory_info().rss)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T12:04:30.473409Z","iopub.execute_input":"2022-01-02T12:04:30.473881Z","iopub.status.idle":"2022-01-02T12:04:31.215818Z","shell.execute_reply.started":"2022-01-02T12:04:30.473848Z","shell.execute_reply":"2022-01-02T12:04:31.215151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(unet , \"/kaggle/working/unet_model1-2_2\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T11:02:21.667945Z","iopub.execute_input":"2022-01-02T11:02:21.669444Z","iopub.status.idle":"2022-01-02T11:02:21.901541Z","shell.execute_reply.started":"2022-01-02T11:02:21.669397Z","shell.execute_reply":"2022-01-02T11:02:21.900715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##view training file sets ###\n## 確認一下training_loader 有沒有沒配對好 ##\n## 確認一下到底要不要再加上T.RandomAutocontrast(p=1) ##\n## lossfunction 確認一下 方式##\n## accuracy 跟 callback function##\n## whole dataset normalization 也是怪怪的 ，有沒有好方法可以不要一定餵定值##\n%matplotlib inline\nfor data in training_dataset :\n    inputs, labels = data #batched\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"import torch\ntorch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\"\"\"\nprint(device1)\n%matplotlib inline\nmodel = torch.load(\"./unet_model1-2_2\")\nmodel.to(device1)\nfor data in testing_dataloader:\n    \n    inputs, labels = data #batched\n    inputs = inputs.to(device1)\n    labels = labels.to(device1)\n    test_output = model(inputs)\n    #print(test_output.cpu().data.numpy())\n    test_output = np.squeeze(test_output.cpu().data.numpy() , axis = 0)\n    test_output = np.transpose(test_output , (2 , 1 , 0))\n    labels = np.squeeze(labels.cpu().data.numpy() , axis = 0)\n    labels = np.transpose(labels , (2 , 1 , 0))\n    plt.imshow(test_output)\n    plt.title(\"output\")\n    plt.show()\n    plt.imshow(labels)\n    plt.title(\"label\")\n    plt.show()\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T11:33:47.219395Z","iopub.execute_input":"2022-01-02T11:33:47.220071Z","iopub.status.idle":"2022-01-02T11:33:52.50097Z","shell.execute_reply.started":"2022-01-02T11:33:47.220027Z","shell.execute_reply":"2022-01-02T11:33:52.500306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
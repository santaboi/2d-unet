{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j6WJ26MvGVd",
        "outputId": "58ee8299-e302-4e21-b620-1996a2d25425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rGfGuXo9vfzp"
      },
      "outputs": [],
      "source": [
        "\"\"\"cfg\"\"\"\n",
        "#only use T1C data (non PR)\n",
        "#/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/PR/Flair/JPEGImages\n",
        "#whole brain\n",
        "non_T1C_data = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/non_PR/T1c/JPEGImages\"  \n",
        "PR_T1C_data = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/PR/T1c/JPEGImages\"\n",
        "\n",
        "non_T1_data = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/non_PR/T1/JPEGImages\"\n",
        "PR_T1_data = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/PR/T1/JPEGImages\"\n",
        "\n",
        "non_Flair_data = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/non_PR/Flair/JPEGImages\"\n",
        "PR_Flair_data = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/PR/Flair/JPEGImages\"\n",
        "\n",
        "non_T2_data = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/non_PR/T2/JPEGImages\"\n",
        "PR_T2_data = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/PR/T2/JPEGImages\"\n",
        "#mask (ground truth)\n",
        "non_T1C_target = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/non_PR/T1c/SegmentationClassPNG\" \n",
        "PR_T1C_target = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/PR/T1c/SegmentationClassPNG\"\n",
        "\n",
        "non_T1_target = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/non_PR/T1/SegmentationClassPNG\" \n",
        "PR_T1_target = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/PR/T1/SegmentationClassPNG\"\n",
        "\n",
        "non_Flair_target = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/non_PR/Flair/SegmentationClassPNG\" \n",
        "PR_Flair_target = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/PR/Flair/SegmentationClassPNG\"\n",
        "\n",
        "non_T2_target = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/non_PR/T2/SegmentationClassPNG\" \n",
        "PR_T2_target = \"/content/drive/MyDrive/Colab Notebooks/2d unet/data/PSPF_voc_data/PR/T2/SegmentationClassPNG\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnCXY4uNvBP_",
        "outputId": "9f1cf6e5-b4e2-4209-d8aa-d23eca90cbf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8c878049d0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader , Dataset \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#from cfg import *\n",
        "torch.manual_seed(6666)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[93, 85, 33, 72, 86, 24, 83, 88, 34, 36, 28, 37, 0, 68, 57, 58, 52, 15, 94, 35, 75, 76, 78, 90, 3, 11, 40, 47, 27, 51]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "#Generate 5 random numbers between 10 and 30\n",
        "randomlist = random.sample(range(0, 95), )\n",
        "print(randomlist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-drvvwwKvBQD"
      },
      "source": [
        "use constantpad2d() to resize "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ntfXrZKFvBQF"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torchvision.transforms as T \n",
        "from torchvision.transforms.functional import hflip , vflip\n",
        "\n",
        "class Total_dataset(Dataset):\n",
        "    def __init__(self, inputs: list, targets: list, transform=None) -> None:\n",
        "        super().__init__()\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "    def __getitem__(self , index : int  , transform = None):\n",
        "        #是否有辦法用path + file name取用data\n",
        "        input_img = self.inputs[index]\n",
        "        target_img = self.targets[index]\n",
        "        \n",
        "        x_data , y_data = cv2.imread(input_img) , cv2.imread(target_img)\n",
        "        \n",
        "        #print(x_data.shape)\n",
        "        #print(y_data.shape)\n",
        "        \n",
        "        \n",
        "        #resize\n",
        "        if x_data.shape != (512 , 512 , 3) :\n",
        "            x_data = cv2.resize(x_data , (512 , 512))\n",
        "        if y_data.shape != (512 , 512 , 3) :\n",
        "            y_data = cv2.resize(y_data , (512 ,512))\n",
        "\n",
        "        # turn to torch (typecasting)\n",
        "\n",
        "        #data augmentaion if true\n",
        "        if self.transform != None : \n",
        "            #x_data , y_data = self.transform(x_data , y_data)\n",
        "            for t in self.transform :\n",
        "                if t == \"T.Normalize([1 , 1 , 1] , [1 , 1 , 1])\" :\n",
        "                    \"\"\"\n",
        "                    x y mean0 tensor(0.2302) tensor(0.0111)\n",
        "                    x y mean1 tensor(0.1842) tensor(0.0111)\n",
        "                    x y mean2 tensor(0.1870) tensor(0.0111)\n",
        "                    x y std0 tensor(0.2334) tensor(0.0737)\n",
        "                    x y std01 tensor(0.1999) tensor(0.0737)\n",
        "                    x y std2 tensor(0.1987) tensor(0.0737)\n",
        "                    \"\"\"\n",
        "                    #normalized with whole dataset mean and std (not batchwise)\n",
        "                    img_normalize = T.Normalize([0.2302 , 0.1842 , 0.1870] , [0.2334 , 0.1999 , 0.1987])\n",
        "                    x_data = img_normalize(x_data)\n",
        "                    label_normalize = T.Normalize([0.0111 , 0.0111 , 0.0111 ] , [0.0737 , 0.0737 , 0.0737]) \n",
        "                    y_data = label_normalize(y_data)\n",
        "                elif t == \"T.RandomHorizontalFlip(p=1)\" :\n",
        "                    if torch.rand(1)< 0.5 :\n",
        "                        x_data = hflip(x_data)\n",
        "                        y_data = hflip(y_data)\n",
        "                elif t == \"T.RandomVerticalFlip(p=1)\" :\n",
        "                    if torch.rand(1)< 0.5 :\n",
        "                        x_data = vflip(x_data)\n",
        "                        y_data = vflip(y_data)\n",
        "                        \n",
        "\n",
        "                elif t == \"T.RandomRotation(degrees=(360 , 360))\" : \n",
        "                    if torch.rand(1)< 0.5 :\n",
        "                        angle = int(torch.rand(1)*360)\n",
        "                        rotate_funct = T.RandomRotation(degrees=(angle, angle))\n",
        "                        x_data = rotate_funct(x_data)\n",
        "                        y_data = rotate_funct(y_data)\n",
        "                else :\n",
        "                    x_data = t(x_data)\n",
        "                    y_data =t(y_data)\n",
        "                \n",
        "        #x_data, y_data = torch.from_numpy(x_data).type(torch.float32), torch.from_numpy(y_data).type(torch.float32)\n",
        "        x_data = torch.permute(x_data , (1, 2 , 0))\n",
        "        y_data = torch.permute(y_data , (1 , 2 , 0))\n",
        "        y_data = y_data[: , : , 2] #edit to the last channel\n",
        "        y_data = np.expand_dims( y_data, axis= -1) #(512 512) -> (512 512 1)\n",
        "        return x_data , y_data  #torch\n",
        "\n",
        "        #torch or numpy to chose\n",
        "\n",
        "        \n",
        "        \n",
        "    \n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "IChysDPjvBQG",
        "outputId": "841fa361-afd9-4643-bb25-4346e6cafc4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'20947834', '27472711', '31046225', '15525495', '13661917', '27237207', '27710844', '24237245', '26082459', '30268702', '30871154', '17244854', '18456622', '27931321', '15176128', '29816081', '14041674', '25825974', '29729120', '10027124', '28267864', '15552568', '31406726', '21105320', '28248060', '19425238', '30920239', '26434694', '26073373', '25385854', '31445157', '26608196', '30732894', '11009708', '30517836', '20483981', '29285707', '19315335', '33056266', '26658418', '18765851', '29177415', '80190941', '28358688', '27103788', '21381973', '13488672', '29301889', '21372392', '12261283', '16113441', '11775010', '31001430', '27607264', '22296689', '52847319'}\n",
            "success\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print(len(name_set))\\nprint(len(name_set2))\\nprint(len(non_name_set))\\nprint(len(PR_name_set))'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "non_name_set = set()\n",
        "PR_name_set = set()\n",
        "name_set = set()\n",
        "total_data_path = [non_T1C_data , non_T1_data , non_Flair_data , non_T2_data , PR_T1C_data , PR_T1_data , PR_Flair_data  , PR_T2_data]\n",
        "count1 = 0\n",
        "for folder_name in total_data_path :\n",
        "    for name in os.listdir(folder_name) :\n",
        "        name = name.strip('.jpg').strip('.json')\n",
        "        if name == 'ipynb_checkpoint' :\n",
        "            continue\n",
        "        name_set.add(name)\n",
        "        if count1 <= 3 :\n",
        "            non_name_set.add(name)\n",
        "        else :\n",
        "            PR_name_set.add(name)\n",
        "    count1 += 1\n",
        "#print(name_set)\n",
        "\n",
        "\n",
        "non_name_set2 = set()\n",
        "PR_name_set2 = set()\n",
        "name_set2 = set()\n",
        "count2 = 0\n",
        "total_target_path = [ non_T1C_target , non_T1_target , non_Flair_target  , non_T2_target , PR_T1C_target , PR_T1_target ,  PR_Flair_target , PR_T2_target ]\n",
        "for folder_name2 in total_target_path :\n",
        "    for name in os.listdir(folder_name2):\n",
        "        name = name.strip('.png')\n",
        "        if name == 'ipynb_checkpoint':\n",
        "            continue\n",
        "        name_set2.add(name)\n",
        "        if count2 <= 3 :\n",
        "            non_name_set2.add(name)\n",
        "        else :\n",
        "            PR_name_set2.add(name)\n",
        "    count2 += 1\n",
        "print(name_set2)\n",
        "\n",
        "\n",
        "#same patients set (make sure no mismatch)\n",
        "if name_set2 == name_set :\n",
        "    print('success')\n",
        "\"\"\"print(len(name_set))\n",
        "print(len(name_set2))\n",
        "print(len(non_name_set))\n",
        "print(len(PR_name_set))\"\"\"\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "5IExHQzxvBQH",
        "outputId": "05e9f3a3-a99a-4ad5-bdf1-7f892e55e4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "224\n",
            "x_shape torch.Size([224, 512, 512, 3])\n",
            "y_shape torch.Size([224, 512, 512, 1])\n",
            "x y mean0 tensor(0.0992) tensor(0.0131)\n",
            "x y mean1 tensor(0.1579) tensor(0.0131)\n",
            "x y mean2 tensor(0.1793) tensor(0.0131)\n",
            "x y std0 tensor(0.1205) tensor(0.0801)\n",
            "x y std01 tensor(0.1921) tensor(0.0801)\n",
            "x y std2 tensor(0.2163) tensor(0.0801)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'x y mean0 tensor(0.1291) tensor(0.0205)\\nx y mean1 tensor(0.0905) tensor(0.0205)\\nx y mean2 tensor(0.1105) tensor(0.0205)\\nx y std0 tensor(0.1400) tensor(0.0993)\\nx y std01 tensor(0.1097) tensor(0.0993)\\nx y std2 tensor(0.1298) tensor(0.0993)'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#same patient (same index)\n",
        "total_data_list = []\n",
        "total_target_list =[]  \n",
        "for name in non_name_set :\n",
        "    name1 = name + \".jpg\"\n",
        "    name2 = name + \".png\"\n",
        "    total_data_list.append(os.path.join(non_T1C_data , name1))\n",
        "    total_data_list.append(os.path.join(non_T1_data , name1))\n",
        "    total_data_list.append(os.path.join(non_Flair_data , name1))\n",
        "    total_data_list.append(os.path.join(non_T2_data , name1))\n",
        "    total_target_list.append(os.path.join(non_T1C_target , name2))\n",
        "    total_target_list.append(os.path.join(non_T1_target , name2))\n",
        "    total_target_list.append(os.path.join(non_Flair_target , name2))\n",
        "    total_target_list.append(os.path.join(non_T2_target , name2)) \n",
        "\n",
        "for name in PR_name_set :\n",
        "    name1 = name + \".jpg\"\n",
        "    name2 = name + \".png\"\n",
        "    total_data_list.append(os.path.join(PR_T1C_data , name1))\n",
        "    total_data_list.append(os.path.join(PR_T1_data , name1))\n",
        "    total_data_list.append(os.path.join(PR_Flair_data , name1))\n",
        "    total_data_list.append(os.path.join(PR_T2_data , name1))\n",
        "    total_target_list.append(os.path.join(PR_T1C_target , name2))\n",
        "    total_target_list.append(os.path.join(PR_T1_target , name2))\n",
        "    total_target_list.append(os.path.join(PR_Flair_target , name2))\n",
        "    total_target_list.append(os.path.join(PR_T2_target , name2))   \n",
        "\n",
        "train_data_list = total_data_list[0 : int(len(total_data_list)*0.8)] #80%data\n",
        "train_target_list =  total_target_list[0 : int(len(total_target_list)*0.8) ] #80%target\n",
        "\n",
        "test_data_list = total_data_list[int(len(total_data_list)*0.8) : len(total_data_list)] #20%data\n",
        "test_target_list = total_target_list[int(len(total_target_list)*0.8) : len(total_target_list)] #20%target\n",
        "\n",
        "#initial img visualize\n",
        "\"\"\"count , count2 = 0 , 0\n",
        "for img1 in total_data_list:\n",
        "    img1 = cv2.imread(img1)\n",
        "    print(type(img1))\n",
        "    plt.imshow(img1)\n",
        "    plt.show()\n",
        "    print(img1.shape)\n",
        "    count += 1\n",
        "    if count > 5 : break\n",
        "for img2 in total_target_list:\n",
        "    img2 = cv2.imread(img2)\n",
        "    print(type(img2))\n",
        "    plt.imshow(img2)\n",
        "    plt.show()\n",
        "    print(img2.shape)\n",
        "    count2 += 1\n",
        "    if count2 > 5: break\"\"\"\n",
        "\n",
        "\n",
        "#std and mean calculated\n",
        "#total dataset\n",
        "total_dataset = Total_dataset(total_data_list ,\n",
        "                              total_target_list,\n",
        "                              transform= [T.ToTensor()]\n",
        ")\n",
        "print(len(total_dataset))\n",
        "total_dataloader = DataLoader(total_dataset , batch_size= len(total_dataset) , shuffle= False)\n",
        "#total_dataloader = DataLoader(total_dataset , batch_size= len(total_data_list) , shuffle= False)\n",
        "\n",
        "x , y = next(iter(total_dataloader))\n",
        "print(\"x_shape\", x.shape)\n",
        "print(\"y_shape\" , y.shape)\n",
        "\n",
        "\n",
        "#img visualize after to_tensor\n",
        "\"\"\"for index in range(5) :\n",
        "    #cv2.imshow(f\"{index}.jpg\" , x[index , : , : , :].detach().cpu().numpy())\n",
        "    #cv2.imshow(f\"{index}.png\" , y[index , : , : , : ].detach().cpu().numpy())\n",
        "    plt.imshow(x[index , : , : , :])\n",
        "    plt.show()\n",
        "    plt.imshow(y[index , : , : , :])\n",
        "    plt.show()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "print(\"x y mean0\" ,x[0].mean() , y[0].mean()) #ch1\n",
        "print(\"x y mean1\" ,x[1].mean() , y[1].mean()) #ch2\n",
        "print(\"x y mean2\" ,x[2].mean() , y[2].mean()) #ch3\n",
        "print(\"x y std0\" , x[0].std() , y[0].std()) #ch1\n",
        "print(\"x y std01\" , x[1].std() , y[1].std()) #ch2\n",
        "print(\"x y std2\" , x[2].std() , y[2].std() ) #ch3 \n",
        "\n",
        "\"\"\"x y mean0 tensor(0.1291) tensor(0.0205)\n",
        "x y mean1 tensor(0.0905) tensor(0.0205)\n",
        "x y mean2 tensor(0.1105) tensor(0.0205)\n",
        "x y std0 tensor(0.1400) tensor(0.0993)\n",
        "x y std01 tensor(0.1097) tensor(0.0993)\n",
        "x y std2 tensor(0.1298) tensor(0.0993)\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo1JHACSvBQI"
      },
      "source": [
        "# data augmentation\n",
        "可能問題 :\n",
        "    random transform data_x data_y 沒有對到(機率)\n",
        "    \n",
        "    目前label 全黑 (solve : take the last channel)\n",
        "    permute 可能有問題 \n",
        "    label根本沒對到tumor位置 (1 , 2 , 0) (2 , 1 , 0)不知道為啥整個圖轉掉\n",
        "    \n",
        "    為啥mean 跟 standard每次跑數字都不同???????"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5iY7HuOvBQI",
        "outputId": "99d51146-3895-43e7-cf71-6cc7b667c88c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "179\n",
            "torch.Size([900, 512, 512, 3])\n",
            "torch.Size([900, 512, 512, 1])\n",
            "torch.Size([45, 512, 512, 3]) torch.Size([45, 512, 512, 1])\n",
            "train_x = shape: torch.Size([60, 512, 512, 3]); type: torch.float32\n",
            "tensor([[[0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        [[0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        [[0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0040, 0.0040, 0.0040],\n",
            "         [0.0040, 0.0040, 0.0040],\n",
            "         [0.0040, 0.0040, 0.0040]],\n",
            "\n",
            "        [[0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0040, 0.0040, 0.0040],\n",
            "         [0.0040, 0.0040, 0.0040],\n",
            "         [0.0040, 0.0040, 0.0040]],\n",
            "\n",
            "        [[0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0040, 0.0040, 0.0040],\n",
            "         [0.0040, 0.0040, 0.0040],\n",
            "         [0.0040, 0.0040, 0.0040]]])\n",
            "train_y = shape: torch.Size([60, 512, 512, 1]); type: torch.float32\n",
            "train_x = min: 0.0; max: 1.0\n",
            "train_y = shape: torch.Size([60, 512, 512, 1]); class: tensor([0.0000, 0.0078, 0.0156, 0.0221, 0.0234, 0.0312, 0.0391, 0.0469, 0.0547,\n",
            "        0.0625, 0.0703, 0.0781, 0.0859, 0.0938, 0.1016, 0.1094, 0.1172, 0.1250,\n",
            "        0.1328, 0.1406, 0.1484, 0.1562, 0.1641, 0.1719, 0.1797, 0.1875, 0.1953,\n",
            "        0.2031, 0.2109, 0.2188, 0.2266, 0.2344, 0.2422, 0.2500, 0.2578, 0.2656,\n",
            "        0.2734, 0.2813, 0.2891, 0.2969, 0.3047, 0.3125, 0.3203, 0.3281, 0.3359,\n",
            "        0.3438, 0.3516, 0.3594, 0.3672, 0.3750, 0.3828, 0.3906, 0.3984, 0.4062,\n",
            "        0.4141, 0.4219, 0.4297, 0.4375, 0.4453, 0.4531, 0.4609, 0.4688, 0.4766,\n",
            "        0.4844, 0.4922, 0.5000, 0.5078, 0.5156, 0.5234, 0.5312, 0.5391, 0.5469,\n",
            "        0.5547, 0.5625, 0.5703, 0.5781, 0.5859, 0.5938, 0.6016, 0.6094, 0.6172,\n",
            "        0.6250, 0.6328, 0.6406, 0.6484, 0.6562, 0.6641, 0.6719, 0.6797, 0.6875,\n",
            "        0.6953, 0.7031, 0.7109, 0.7188, 0.7266, 0.7344, 0.7422, 0.7500, 0.7578,\n",
            "        0.7656, 0.7734, 0.7813, 0.7891, 0.7969, 0.8047, 0.8125, 0.8203, 0.8281,\n",
            "        0.8359, 0.8438, 0.8516, 0.8594, 0.8672, 0.8750, 0.8828, 0.8906, 0.8984,\n",
            "        0.9062, 0.9141, 0.9219, 0.9297, 0.9375, 0.9453, 0.9531, 0.9609, 0.9688,\n",
            "        0.9766, 0.9844, 0.9922, 1.0000]); type: torch.float32\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#目前尚未 rescale 跟 normalize\n",
        "print(len(train_data_list))\n",
        "#rename transform\n",
        "normal = \"T.Normalize([1 , 1 , 1] , [1 , 1 , 1])\"\n",
        "v_flip = \"T.RandomVerticalFlip(p=1)\"\n",
        "h_flip = \"T.RandomHorizontalFlip(p=1)\"\n",
        "r_rotate = \"T.RandomRotation(degrees=(360 , 360))\"\n",
        "#note : rewrite every probability functions in Total_dataset()\n",
        "train_dataset = Total_dataset(train_data_list,\n",
        "                             train_target_list ,\n",
        "                             transform= [T.ToTensor() , normal , \n",
        "                             v_flip , \n",
        "                             h_flip , \n",
        "                             r_rotate,\n",
        "                             T.RandomAutocontrast(p=1) ,\n",
        "                             ])\n",
        "                             \n",
        "#transform should add                \n",
        "training_dataloader = DataLoader(train_dataset,\n",
        "                                 batch_size=60,\n",
        "                                 shuffle=True)\n",
        "\n",
        "test_dataset = Total_dataset(test_data_list ,\n",
        "                            test_target_list ,\n",
        "                            transform= [ T.ToTensor() , T.Normalize([1 , 1 , 1] , [1 , 1 , 1]) , T.RandomAutocontrast(p=1)])\n",
        "\n",
        "testing_dataloader = DataLoader(test_dataset,\n",
        "                                 batch_size=45,\n",
        "                                 shuffle=True)\n",
        "\n",
        "\n",
        "\"\"\"change to keras accepted dtype(train test val build)\"\"\"\n",
        "#dtype (torch.float32) torch.size(batchsize , 3 , 512 , 512)\n",
        "#take total 170 imgs (17 * 10)\n",
        "\n",
        "\n",
        "train_x, train_y = next(iter(training_dataloader))\n",
        "\"\"\"for index in range(50) :\n",
        "    plt.imshow(train_x[index , : , : , :])\n",
        "    plt.show()\n",
        "    plt.imshow(train_y[index , : , : , :])\n",
        "    plt.show()\"\"\"\n",
        "\n",
        "total_train_img = train_x\n",
        "total_train_lbl = train_y\n",
        "batch_count = 14\n",
        "for i in range(batch_count) :\n",
        "    train_x, train_y = next(iter(training_dataloader))\n",
        "    total_train_img = torch.cat((total_train_img , train_x) , dim= 0)\n",
        "    total_train_lbl = torch.cat((total_train_lbl , train_y) , dim = 0)\n",
        "print(total_train_img.shape)\n",
        "print(total_train_lbl.shape)\n",
        "total_val_img = total_train_img[0 : int(0.2* len(total_train_img))]\n",
        "total_val_lbl = total_train_lbl[0 : int(0.2* len(total_train_lbl))]\n",
        "total_train_img = total_train_img[int(0.2* len(total_train_img)) : ]\n",
        "total_train_lbl = total_train_lbl[int(0.2* len(total_train_lbl)) : ]\n",
        "    \n",
        "test_x , test_y = next(iter(testing_dataloader))\n",
        "print(test_x.shape , test_y.shape)\n",
        "\n",
        "\n",
        "#all img and label size is (512 , 512 , 3)\n",
        "print(f'train_x = shape: {train_x.shape}; type: {train_x.dtype}')\n",
        "print(train_x[0])\n",
        "print(f'train_y = shape: {train_y.shape}; type: {train_y.dtype}')\n",
        "print(f'train_x = min: {train_x.min()}; max: {train_x.max()}')\n",
        "print(f'train_y = shape: {train_y.shape}; class: {train_y.unique()}; type: {train_y.dtype}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0sA-v_0x1SE",
        "outputId": "e83f3e51-f4f2-4a63-aac2-1e5e64cba5b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45\n"
          ]
        }
      ],
      "source": [
        "print(len(test_data_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH00P6puvBQJ",
        "outputId": "2016b946-22c7-4a90-9752-4dcbfd9d91bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(720, 512, 512, 3)\n",
            "(720, 512, 512, 1)\n",
            "(45, 512, 512, 3)\n",
            "(45, 512, 512, 1)\n",
            "(180, 512, 512, 3)\n",
            "(180, 512, 512, 1)\n"
          ]
        }
      ],
      "source": [
        "np_total_train_img = total_train_img.detach().cpu().numpy()\n",
        "np_total_train_lbl = total_train_lbl.detach().cpu().numpy()\n",
        "np_total_test_img = test_x.detach().cpu().numpy()\n",
        "np_total_test_lbl = test_y.detach().cpu().numpy()\n",
        "np_total_val_img = total_val_img.detach().cpu().numpy()\n",
        "np_total_val_lbl = total_val_lbl.detach().cpu().numpy()\n",
        "print(np_total_train_img.shape)\n",
        "print(np_total_train_lbl.shape)\n",
        "\n",
        "print(np_total_test_img.shape)\n",
        "print(np_total_test_lbl.shape)\n",
        "\n",
        "print(np_total_val_img.shape)\n",
        "print(np_total_val_lbl.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nv-YVvq_vBQJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as keras\n",
        "\n",
        "#layer visualized\n",
        "import tensorflow as tf\n",
        "\"\"\"input_shape = (1 ,512, 512, 3)\n",
        "x = tf.random.normal(input_shape)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def unet(pretrained_weights = None,input_size = (512 , 512 , 3)):\n",
        "    #Dropout(rate = 0.5) -> rate: Float between 0 and 1. Fraction of the input units to drop.\n",
        "    #->  as to prevent from overfitting\n",
        "    \n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    #pool1 -> (_ , 256 , 256 , 64)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    #pool2 -> (_ , 128 , 128 , 128)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    #pool3 -> (_ , 64 , 64 , 256)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "    #pool4 -> (_ , 32 , 32 , 512)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "    #drop5 -> (_ ,  32, 32, 1024)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    #up6 (1, 64, 64, 512)\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "    #conv6 ->(1, 64, 64, 512)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    #up7 (1, 128, 128, 256)\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "    #conv7 (1, 128, 128, 256)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    #up8 (1, 256, 256, 128)\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    #up9 (1, 512, 512, 64)\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    #merge9 (1, 512, 512, 128)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding =  'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "    #conv10 ()\n",
        "\n",
        "    model = Model(inputs, conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    #model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFXLeQGIvBQK",
        "outputId": "1697dde6-2c6e-4b29-d1a1-16ccabe44d92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ]
        }
      ],
      "source": [
        "#hyperparameters\n",
        "#batch_size = 10\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DQmCT-w5vBQL",
        "outputId": "e6d13009-4d90-484a-cabd-b4d6587f2737"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model is fitting.......\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a65d86c1f1b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model is fitting.......\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#model.fit_generator(training_dataloader,steps_per_epoch=300,epochs=1,callbacks=[model_checkpoint])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_total_train_img\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_total_train_lbl\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp_total_val_img\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnp_total_val_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[5,128,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model/conv2d_20/Conv2D/Conv2DBackpropInput\n (defined at /usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2908]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/model/conv2d_20/Conv2D/Conv2DBackpropInput:\nIn[0] gradient_tape/model/conv2d_20/Conv2D/ShapeN:\t\nIn[1] model/conv2d_20/Conv2D/ReadVariableOp (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py:238)\t\nIn[2] gradient_tape/model/conv2d_20/ReluGrad:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n>>>     handler_func(fileobj, events)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-13-a65d86c1f1b2>\", line 6, in <module>\n>>>     model.fit(x = np_total_train_img , y = np_total_train_lbl , batch_size = 5 , epochs= 10 , steps_per_epoch = 60 ,callbacks=[model_checkpoint] , validation_data= (np_total_val_img , np_total_val_img))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 531, in minimize\n>>>     loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> "
          ]
        }
      ],
      "source": [
        "\"\"\"training and saving\"\"\"\n",
        "model = unet()\n",
        "model_checkpoint = ModelCheckpoint('CMtumor_unet1.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "print(\"model is fitting.......\")\n",
        "#model.fit_generator(training_dataloader,steps_per_epoch=300,epochs=1,callbacks=[model_checkpoint])\n",
        "model.fit(x = np_total_train_img , y = np_total_train_lbl , batch_size = 5 , epochs= 10 , steps_per_epoch = 60 ,callbacks=[model_checkpoint] , validation_data= (np_total_val_img , np_total_val_img))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phExODS25POK"
      },
      "outputs": [],
      "source": [
        "\"\"\"garbage collect\"\"\"\n",
        "import gc\n",
        "for _ in range(10):\n",
        "  gc.collect()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY-q-dSIv6B3"
      },
      "outputs": [],
      "source": [
        "\"\"\"evaluate model\"\"\"\n",
        "unet_model = model.load_weights(\"/content/CMtumor_unet2.hdf5\")\n",
        "\n",
        "model.evaluate(x = np_total_test_img , y = np_total_test_lbl , batch_size = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHTXNCiLfxQH"
      },
      "outputs": [],
      "source": [
        "\"\"\"test results\"\"\"\n",
        "print(np_total_test_img[0:5 , : , : , :].shape)\n",
        "output = model.predict(np_total_test_img[0:5, : , : , :])\n",
        "print(output.shape)\n",
        "for index in range(5):\n",
        "  plt.imshow(np_total_test_img[index , : , : , :])\n",
        "  plt.show()\n",
        "  \n",
        "  plt.imshow(output[index, : , : , :].squeeze())\n",
        "  plt.show()\n",
        "  #masked\n",
        "  mask = np.concatenate((output[index, : , : , :] , output[index, : , : , ] , output[index, : , : , :]) , axis = 2)\n",
        "  per_mask = np_total_test_img[index , : , : , :] * mask\n",
        "  plt.imshow(per_mask)\n",
        "  plt.show()\n",
        "  #print(output[index , : , : , :])\n",
        "  print(\"####################################################################################################################################\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BHsCbismszJ"
      },
      "outputs": [],
      "source": [
        "\"\"\"determine threshold\"\"\"\n",
        "plt.imshow(np_total_test_lbl[1].squeeze())\n",
        "\"\"\"cc_count = 0\n",
        "for ix , iy in np.ndindex(np_total_test_lbl[1].squeeze().shape) :\n",
        "  if np_total_test_lbl[1].squeeze()[ix , iy] != 0 :\n",
        "    cc_count += 1\n",
        "    print(np_total_test_lbl[1].squeeze()[ix , iy])\n",
        "print(cc_count)\"\"\"\n",
        "#mask\n",
        "for index in range(5) :\n",
        "  masked_output = np_total_test_lbl[index] * output[index]  \n",
        "  plt.imshow(masked_output.squeeze())\n",
        "  plt.show()\n",
        "  print(\"min value\" , masked_output.min() , \"max value\" , masked_output.max())\n",
        "  print(\"mean\" , masked_output.mean())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "dataloader.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2b562ed37188020c8a8c07b69b9eae1a2662f56daf78cc992f9676fd3c0f765c"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 64-bit ('2dunet': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

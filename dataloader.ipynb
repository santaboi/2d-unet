{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16c07c1c030>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader , Dataset \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cfg import *\n",
    "torch.manual_seed(6666)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use constantpad2d() to resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torchvision.transforms as T \n",
    "count = 0 \n",
    "\n",
    "class Total_dataset(Dataset):\n",
    "    def __init__(self, inputs: list, targets: list, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    def __getitem__(self , index : int  , transform = None):\n",
    "        #是否有辦法用path + file name取用data\n",
    "        input_img = self.inputs[index]\n",
    "        target_img = self.targets[index]\n",
    "        \n",
    "        x_data , y_data = cv2.imread(input_img) , cv2.imread(target_img)\n",
    "        \n",
    "        \"\"\"global count \n",
    "        cv2.imwrite(f'./img_data/{count}.jpg' , x_data)\n",
    "        print(type(x_data))\n",
    "        print(type(y_data))\n",
    "        count += 1\"\"\"\n",
    "        \n",
    "        #resize\n",
    "        if x_data.shape != [512 , 512 , 3] :\n",
    "            x_data = cv2.resize(x_data , (512 , 512))\n",
    "        if y_data.shape != [512 , 512 , 3] :\n",
    "            y_data = cv2.resize(y_data , (512 ,512))\n",
    "\n",
    "        # turn to torch (typecasting)\n",
    "\n",
    "        #data augmentaion if true\n",
    "        if self.transform != None : \n",
    "            #x_data , y_data = self.transform(x_data , y_data)\n",
    "            for t in self.transform :\n",
    "                if t == T.Normalize([1 , 1 , 1] , [1 , 1 , 1]) :\n",
    "                    \"\"\"\n",
    "                    #calculated in tensor type\n",
    "                    x y mean0 tensor(0.0806) tensor(0.0015)\n",
    "                    x y mean1 tensor(0.1362) tensor(0.0015)\n",
    "                    x y mean2 tensor(0.1254) tensor(0.0015)\n",
    "                    x y std0 tensor(0.1267) tensor(0.0270)\n",
    "                    x y std01 tensor(0.1948) tensor(0.0270)\n",
    "                    x y std2 tensor(0.1966) tensor(0.0270)\n",
    "                    \"\"\"\n",
    "                    #normalized with whole dataset mean and std (not batchwise)\n",
    "                    x_data = T.Normalize([0.0806 , 0.1362 , 0.1254] , [0.1267 , 0.1948 , 0.1966])\n",
    "                    y_data = T.Normalize([0.0015 , 0.0015 , 0.0015] , [0.0270 , 0.0270 , 0.0270]) \n",
    "                else :\n",
    "                    x_data = t(x_data)\n",
    "                    y_data =t(y_data)\n",
    "                \n",
    "        #x_data, y_data = torch.from_numpy(x_data).type(torch.float32), torch.from_numpy(y_data).type(torch.float32)\n",
    "        \n",
    "        return x_data , y_data  #torch\n",
    "\n",
    "        #torch or numpy to chose\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'17244854', '28267864', '15525495', '27103788', '20483981', '30732894', '18765851', '80190941', '24237245', '33056266', '28358688', '11009708', '27237207', '27710844', '28248060', '29177415', '25825974', '15176128', '29301889', '26082459', '29729120', '29816081', '22296689', '26658418', '26073373', '31445157', '18456622', '20947834', '16113441', '31406726', '27607264', '13661917', '10027124', '30517836', '26434694', '29285707', '12261283', '26608196', '19425238', '15552568', '21105320', '52847319', '27931321', '30268702', '21372392', '14041674', '19315335', '27472711', '21381973', '13488672', '31001430', '11775010', '31046225', '30920239', '25385854', '30871154'}\n",
      "success\n",
      "fuck2021\n",
      "fuck2023\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  currently using only nonPR (T1c)\n",
    "import os\n",
    "#non_T1C_data = \"./data/PSPF_voc_data/non_PR/T1c/JPEGImages/\" \n",
    "#non_T1C_target = \"./data/PSPF_voc_data/non_PR/T1c/SegmentationClassPNG/\" \n",
    "\n",
    "non_name_set = set()\n",
    "PR_name_set = set()\n",
    "name_set = set()\n",
    "total_data_path = [non_T1C_data , non_T1_data , non_Flair_data , non_T2_data , PR_T1C_data , PR_T1_data , PR_Flair_data  , PR_T2_data]\n",
    "count1 = 0\n",
    "for folder_name in total_data_path :\n",
    "    for name in os.listdir(folder_name) :\n",
    "        name = name.strip('.jpg').strip('.json')\n",
    "        if name == 'ipynb_checkpoint' :\n",
    "            continue\n",
    "        name_set.add(name)\n",
    "        if count1 <= 3 :\n",
    "            non_name_set.add(name)\n",
    "        else :\n",
    "            PR_name_set.add(name)\n",
    "    count1 += 1\n",
    "#print(name_set)\n",
    "\n",
    "\n",
    "non_name_set2 = set()\n",
    "PR_name_set2 = set()\n",
    "name_set2 = set()\n",
    "count2 = 0\n",
    "total_target_path = [ non_T1C_target , non_T1_target , non_Flair_target  , non_T2_target , PR_T1C_target , PR_T1_target ,  PR_Flair_target , PR_T2_target ]\n",
    "for folder_name2 in total_target_path :\n",
    "    for name in os.listdir(folder_name2):\n",
    "        name = name.strip('.png')\n",
    "        if name == 'ipynb_checkpoint':\n",
    "            continue\n",
    "        name_set2.add(name)\n",
    "        if count2 <= 3 :\n",
    "            non_name_set2.add(name)\n",
    "        else :\n",
    "            PR_name_set2.add(name)\n",
    "    count2 += 1\n",
    "print(name_set2)\n",
    "\n",
    "\n",
    "#same patients set (make sure no mismatch)\n",
    "if name_set2 == name_set :\n",
    "    print('success')\n",
    "\"\"\"print(len(name_set))\n",
    "print(len(name_set2))\n",
    "print(len(non_name_set))\n",
    "print(len(PR_name_set))\"\"\"\n",
    "if non_name_set2 == non_name_set :\n",
    "    print(\"fuck2021\")\n",
    "if PR_name_set2 == PR_name_set :\n",
    "    print(\"fuck2023\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x y mean0 tensor(0.0925) tensor(0.0018)\n",
      "x y mean1 tensor(0.1173) tensor(0.0018)\n",
      "x y mean2 tensor(0.1497) tensor(0.0018)\n",
      "x y std0 tensor(0.1365) tensor(0.0297)\n",
      "x y std01 tensor(0.1797) tensor(0.0297)\n",
      "x y std2 tensor(0.2085) tensor(0.0297)\n"
     ]
    }
   ],
   "source": [
    "#same patient (same index)\n",
    "total_data_list = []\n",
    "total_target_list =[]  \n",
    "for name in non_name_set :\n",
    "    name1 = name + \".jpg\"\n",
    "    name2 = name + \".png\"\n",
    "    total_data_list.append(os.path.join(non_T1C_data , name1))\n",
    "    total_data_list.append(os.path.join(non_T1_data , name1))\n",
    "    total_data_list.append(os.path.join(non_Flair_data , name1))\n",
    "    total_data_list.append(os.path.join(non_T2_data , name1))\n",
    "    total_target_list.append(os.path.join(non_T1C_target , name2))\n",
    "    total_target_list.append(os.path.join(non_T1_target , name2))\n",
    "    total_target_list.append(os.path.join(non_Flair_target , name2))\n",
    "    total_target_list.append(os.path.join(non_T2_target , name2)) \n",
    "\n",
    "for name in PR_name_set :\n",
    "    name1 = name + \".jpg\"\n",
    "    name2 = name + \".png\"\n",
    "    total_data_list.append(os.path.join(PR_T1C_data , name1))\n",
    "    total_data_list.append(os.path.join(PR_T1_data , name1))\n",
    "    total_data_list.append(os.path.join(PR_Flair_data , name1))\n",
    "    total_data_list.append(os.path.join(PR_T2_data , name1))\n",
    "    total_target_list.append(os.path.join(PR_T1C_target , name2))\n",
    "    total_target_list.append(os.path.join(PR_T1_target , name2))\n",
    "    total_target_list.append(os.path.join(PR_Flair_target , name2))\n",
    "    total_target_list.append(os.path.join(PR_T2_target , name2))   \n",
    "\n",
    "train_data_list = total_data_list[0 : int(len(total_data_list)*0.8)] #80%data\n",
    "train_target_list =  total_target_list[0 : int(len(total_target_list)*0.8) ] #80%target\n",
    "\n",
    "test_data_list = total_data_list[int(len(total_data_list)*0.8) : len(total_data_list)] #20%data\n",
    "test_target_list = total_target_list[int(len(total_target_list)*0.8) : len(total_target_list)] #20%target\n",
    "\n",
    "\"\"\"#img visualize\n",
    "count , count2 = 0 , 0\n",
    "for img1 in total_data_list:\n",
    "    img1 = cv2.imread(img1)\n",
    "    print(type(img1))\n",
    "    plt.imshow(img1)\n",
    "    plt.show()\n",
    "    print(img1.shape)\n",
    "    count += 1\n",
    "    if count > 10 : break\n",
    "for img2 in total_target_list:\n",
    "    img2 = cv2.imread(img2)\n",
    "    print(type(img2))\n",
    "    plt.imshow(img2)\n",
    "    plt.show()\n",
    "    print(img2.shape)\n",
    "    count2 += 1\n",
    "    if count2 > 10: break\n",
    "\"\"\"\n",
    "\n",
    "#std and mean calculated\n",
    "#total dataset\n",
    "total_dataset = Total_dataset(total_data_list ,\n",
    "                              total_target_list,\n",
    "                              transform= [T.ToTensor()]\n",
    ")\n",
    "total_dataloader = DataLoader(total_dataset , batch_size= len(total_dataset) , shuffle= False)\n",
    "x , y = next(iter(total_dataloader))\n",
    "print(\"x y mean0\" ,x[0].mean() , y[0].mean()) #ch1\n",
    "print(\"x y mean1\" ,x[1].mean() , y[1].mean()) #ch2\n",
    "print(\"x y mean2\" ,x[2].mean() , y[2].mean()) #ch3\n",
    "print(\"x y std0\" , x[0].std() , y[0].std()) #ch1\n",
    "print(\"x y std01\" , x[1].std() , y[1].std()) #ch2\n",
    "print(\"x y std2\" , x[2].std() , y[2].std() ) #ch3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x = shape: torch.Size([1, 3, 512, 512]); type: torch.float32\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "train_y = shape: torch.Size([1, 3, 512, 512]); type: torch.float32\n",
      "train_x = min: 0.0; max: 1.0\n",
      "train_y = shape: torch.Size([1, 3, 512, 512]); class: tensor([0.0000, 0.0078, 0.0156, 0.0234, 0.0312, 0.0391, 0.0469, 0.0547, 0.0625,\n",
      "        0.0703, 0.0781, 0.0937, 0.1016, 0.1172, 0.1250, 0.1406, 0.1484, 0.1562,\n",
      "        0.1719, 0.1797, 0.1875, 0.1953, 0.2109, 0.2187, 0.2266, 0.2344, 0.2578,\n",
      "        0.2656, 0.2734, 0.2891, 0.2969, 0.3125, 0.3203, 0.3437, 0.3516, 0.3594,\n",
      "        0.3672, 0.3750, 0.3906, 0.3984, 0.4062, 0.4141, 0.4219, 0.4297, 0.4375,\n",
      "        0.4453, 0.4531, 0.4609, 0.4844, 0.5078, 0.5156, 0.5234, 0.5312, 0.5469,\n",
      "        0.5547, 0.5625, 0.5703, 0.5859, 0.6094, 0.6172, 0.6328, 0.6484, 0.6562,\n",
      "        0.6641, 0.6719, 0.6875, 0.6953, 0.7109, 0.7187, 0.7344, 0.7500, 0.7578,\n",
      "        0.7812, 0.7891, 0.7969, 0.8047, 0.8125, 0.8203, 0.8281, 0.8437, 0.8516,\n",
      "        0.8594, 0.8750, 0.8906, 0.8984, 0.9062, 0.9141, 0.9219, 0.9297, 0.9375,\n",
      "        0.9531, 0.9609, 0.9687, 0.9766, 0.9844, 0.9922, 1.0000]); type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#目前尚未 rescale 跟 normalize\n",
    "train_dataset = Total_dataset(train_data_list,\n",
    "                             train_target_list ,\n",
    "                             transform= [T.ToTensor() , T.Normalize([1 , 1 , 1] , [1 , 1 , 1]) , \n",
    "                             #T.ColorJitter(brightness=.5, hue=.3) ,\n",
    "                             T.RandomVerticalFlip(p=0.5) , \n",
    "                             T.RandomHorizontalFlip(p=0.5) , \n",
    "                             T.RandomAutocontrast(p = 0.4) ,\n",
    "                             T.RandomRotation(degrees=(0, 360))\n",
    "                             ])\n",
    "                             \n",
    "#transform should add                \n",
    "training_dataloader = DataLoader(train_dataset,\n",
    "                                 batch_size=1,\n",
    "                                 shuffle=True)\n",
    "\n",
    "test_dataset = Total_dataset(test_data_list ,\n",
    "                            test_target_list ,\n",
    "                            transform= [ T.ToTensor() , T.Normalize([1 , 1 , 1] , [1 , 1 , 1]) , ])\n",
    "\n",
    "testing_dataloader = DataLoader(test_dataset,\n",
    "                                 batch_size=1,\n",
    "                                 shuffle=True)\n",
    "\n",
    "\n",
    "while(True):\n",
    "\n",
    "    train_x, train_y = next(iter(training_dataloader))\n",
    "    if train_x == None and train_y == None :\n",
    "        break\n",
    "    print(f'train_x = shape: {train_x.shape}; type: {train_x.dtype}')\n",
    "    print(f'train_y = shape: {train_y.shape}; type: {train_y.dtype}')\n",
    "test_x , test_y = next(iter(testing_dataloader))\n",
    "\n",
    "\"\"\"\n",
    "#all img and label size is (512 , 512 , 3)\n",
    "print(f'train_x = shape: {train_x.shape}; type: {train_x.dtype}')\n",
    "print(train_x[0])\n",
    "print(f'train_y = shape: {train_y.shape}; type: {train_y.dtype}')\n",
    "print(f'train_x = min: {train_x.min()}; max: {train_x.max()}')\n",
    "print(f'train_y = shape: {train_y.shape}; class: {train_y.unique()}; type: {train_y.dtype}')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "\n",
    "#layer visualized\n",
    "import tensorflow as tf\n",
    "\"\"\"input_shape = (1 ,512, 512, 3)\n",
    "x = tf.random.normal(input_shape)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def unet(pretrained_weights = None,input_size = (512 , 512 , 3)):\n",
    "    #Dropout(rate = 0.5) -> rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "    #->  as to prevent from overfitting\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #pool1 -> (_ , 256 , 256 , 64)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #pool2 -> (_ , 128 , 128 , 128)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    #pool3 -> (_ , 64 , 64 , 256)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    #pool4 -> (_ , 32 , 32 , 512)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    #drop5 -> (_ ,  32, 32, 1024)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    #up6 (1, 64, 64, 512)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    #conv6 ->(1, 64, 64, 512)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    #up7 (1, 128, 128, 256)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    #conv7 (1, 128, 128, 256)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    #up8 (1, 256, 256, 128)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    #up9 (1, 512, 512, 64)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    #merge9 (1, 512, 512, 128)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding =  'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs, conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is fitting.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'torch.utils.data.dataloader.DataLoader'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Temp/ipykernel_13280/2070457348.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CMtumor_unet1.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model is fitting.......\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2028\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2029\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2030\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   2031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2032\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m         \"input: {}, {}\".format(\n\u001b[1;32m--> 991\u001b[1;33m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[0;32m    992\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'torch.utils.data.dataloader.DataLoader'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "\"\"\"training and saving\"\"\"\n",
    "model = unet()\n",
    "model_checkpoint = ModelCheckpoint('CMtumor_unet1.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "print(\"model is fitting.......\")\n",
    "model.fit_generator(training_dataloader,steps_per_epoch=300,epochs=1,callbacks=[model_checkpoint])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b562ed37188020c8a8c07b69b9eae1a2662f56daf78cc992f9676fd3c0f765c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('2dunet': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

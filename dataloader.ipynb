{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader , Dataset \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cfg import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use constantpad2d() to resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "class Total_dataset(Dataset):\n",
    "    def __init__(self, inputs: list, targets: list, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    def __getitem__(self , index : int  , transform = None):\n",
    "        #是否有辦法用path + file name取用data\n",
    "        input_img = self.inputs[index]\n",
    "        target_img = self.targets[index]\n",
    "        \n",
    "        x_data , y_data = cv2.imread(input_img) , cv2.imread(target_img)\n",
    "\n",
    "        if self.transform != None :\n",
    "            x_data , y_data = self.transform(x_data , y_data)\n",
    "        \n",
    "        if x_data.shape != [512 , 512 , 3] :\n",
    "            x_data = cv2.resize(x_data , (512 , 512))\n",
    "        if y_data.shape != [512 , 512 , 3] :\n",
    "            y_data = cv2.resize(y_data , (512 ,512))\n",
    "\n",
    "        # turn to torch (typecasting)\n",
    "        x_data, y_data = torch.from_numpy(x_data).type(torch.float32), torch.from_numpy(y_data).type(torch.float32)\n",
    "        return x_data , y_data  #torch\n",
    "\n",
    "        #torch or numpy to chose\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'25385854', '25825974', '20947834', '31445157', '17244854', '30517836', '28358688', '26658418', '29285707', '26073373', '31001430', '30732894', '18456622', '19425238', '27931321', '29301889', '12261283', '15176128', '28248060', '31406726', '15525495', '28267864', '27472711', '29816081', '15552568', '21105320', '26082459', '29729120', '13488672', '52847319', '26434694', '31046225', '30871154', '30920239', '33056266', '21372392', '21381973', '27237207', '19315335', '22296689', '27103788', '27710844', '27607264'}\n",
      "{'25385854', '25825974', '20947834', '31445157', '17244854', '30517836', '28358688', '26658418', '29285707', '26073373', '31001430', '30732894', '18456622', '19425238', '27931321', '29301889', '12261283', '15176128', '28248060', '31406726', '15525495', '28267864', '27472711', '29816081', '15552568', '21105320', '26082459', '29729120', '13488672', '52847319', '26434694', '31046225', '30871154', '30920239', '33056266', '21372392', '21381973', '27237207', '19315335', '22296689', '27103788', '27710844', '27607264'}\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "#要把 T1c label 丟到全部的type 然後所有type 都要拿來當作data\n",
    "#  currently using only nonPR (T1c)\n",
    "import os\n",
    "#non_T1C_data = \"./data/PSPF_voc_data/non_PR/T1c/JPEGImages/\" \n",
    "#non_T1C_target = \"./data/PSPF_voc_data/non_PR/T1c/SegmentationClassPNG/\" \n",
    "path_list = os.listdir(non_T1C_data)\n",
    "name_set = set()\n",
    "for name in path_list :\n",
    "    name = name.strip('.jpg').strip('.json')\n",
    "    if name == 'ipynb_checkpoint' :\n",
    "        continue\n",
    "    name_set.add(name)\n",
    "print(name_set)\n",
    "path_list = os.listdir(non_T1C_target)\n",
    "name_set2 = set()\n",
    "for name in path_list:\n",
    "    name = name.strip('.png')\n",
    "    if name == 'ipynb_checkpoint':\n",
    "        continue\n",
    "    name_set2.add(name)\n",
    "print(name_set2)\n",
    "\n",
    "#same patients set\n",
    "if name_set2 == name_set :\n",
    "    print('success')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x y mean0 tensor(21.3193) tensor(0.6005)\n",
      "x y mean1 tensor(25.8182) tensor(0.3853)\n",
      "x y mean2 tensor(25.2968) tensor(1.1146)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__call__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Temp/ipykernel_4312/4279563854.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                  shuffle=True)\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\anaconda3\\envs\\2dunet\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Temp/ipykernel_4312/3034052196.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index, transform)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mx_data\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m512\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T \n",
    "\n",
    "#same patient (same index)\n",
    "total_data_list = []\n",
    "total_target_list =[]  \n",
    "for name in name_set :\n",
    "    total_data_list.append(non_T1C_data + name + '.jpg')\n",
    "    total_target_list.append(non_T1C_target + name + '.png')\n",
    "\n",
    "test_data_list = total_data_list[int(len(total_data_list)*0.8) : len(total_data_list)] #20%data\n",
    "test_target_list = total_target_list[int(len(total_target_list)*0.8) : len(total_target_list)] #20%target\n",
    "\n",
    "train_data_list = total_data_list[0 : int(len(total_data_list)*0.8)] #80%data\n",
    "train_target_list =  total_target_list[0 : int(len(total_target_list)*0.8) ] #80%target\n",
    "\n",
    "\"\"\"#img visualize\n",
    "count , count2 = 0 , 0\n",
    "for img1 in train_data_list:\n",
    "    img1 = cv2.imread(img1)\n",
    "    plt.imshow(img1)\n",
    "    plt.show()\n",
    "    print(img1.shape)\n",
    "    count += 1\n",
    "    if count > 10 : break\n",
    "for img2 in target_data_list:\n",
    "    img2 = cv2.imread(img2)\n",
    "    plt.imshow(img2)\n",
    "    plt.show()\n",
    "    print(img2.shape)\n",
    "    count2 += 1\n",
    "    if count2 > 10: break\n",
    "\"\"\"\n",
    "\n",
    "#std and mean calculated\n",
    "#total dataset\n",
    "total_dataset = Total_dataset(total_data_list ,\n",
    "                              total_target_list,\n",
    "                              transform= None\n",
    ")\n",
    "total_dataloader = DataLoader(total_dataset , batch_size= len(total_dataset) , shuffle= False)\n",
    "x , y = next(iter(total_dataloader))\n",
    "print(\"x y mean0\" ,x[0].mean() , y[0].mean()) #ch1\n",
    "print(\"x y mean1\" ,x[1].mean() , y[1].mean()) #ch2\n",
    "print(\"x y mean2\" ,x[2].mean() , y[2].mean()) #ch3\n",
    "\n",
    "\n",
    "\n",
    "#transforms.Normalize(([x[0].mean() , x[1].mean() , x[2].mean()] , [y[0].mean() , y[1].mean() , y[2].mean()]) \n",
    " #                                                                               ,([x[0].std() , x[1].std() , x[2].std()] , [y[0].std() , y[1].std() , y[2].std()]) )\n",
    "#目前尚未 rescale 跟 normalize\n",
    "train_dataset = Total_dataset(train_data_list,\n",
    "                             train_target_list ,\n",
    "                             transform= T.Compose([T.ToTensor()])\n",
    "                            ) \n",
    "#transform should add                \n",
    "training_dataloader = DataLoader(train_dataset,\n",
    "                                 batch_size=10,\n",
    "                                 shuffle=True)\n",
    "\n",
    "test_dataset = Total_dataset(test_data_list ,\n",
    "                            test_target_list ,\n",
    "                            transform= None)\n",
    "                \n",
    "testing_dataloader = DataLoader(test_dataset,\n",
    "                                 batch_size=10,\n",
    "                                 shuffle=True)\n",
    "        \n",
    "train_x, train_y = next(iter(training_dataloader))\n",
    "test_x , test_y = next(iter(testing_dataloader))\n",
    "\n",
    "#img rescale\n",
    "\"\"\"imgs_train = train[0:int (n_input*0.8), :, :,:] / 255 \n",
    "imgs_test = train[int (n_input*0.8):n_input, :, :,:] / 255  \n",
    "imgs_mask_train = label[0:int (n_input*0.8), :, :,:]  / 255 \n",
    "imgs_test_label = label[int (n_input*0.8):n_input, :, :,:]  / 255 \"\"\"\n",
    "\n",
    "\n",
    "print(f'train_x = shape: {train_x.shape}; type: {train_x.dtype}')\n",
    "print(f'train_y = shape: {train_y.shape}; type: {train_y.dtype}')\n",
    "print(f'train_x = min: {train_x.min()}; max: {train_x.max()}')\n",
    "print(f'train_y = shape: {train_y.shape}; class: {train_y.unique()}; type: {train_y.dtype}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "#from data import *\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats.mstats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_10660/619793162.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_10660/619793162.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    def get_model(self):\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class Unet_model():\n",
    "    def __init__(self , img_row = 512 , img_col = 512):\n",
    "        self.img_row = img_row\n",
    "        self.img_col = img_col\n",
    "    \n",
    "    def get_model(self):\n",
    "\n",
    "        inputs = Input((self.img_rows, self.img_cols,3)) #3 channels\n",
    "\t\t\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "\t\t#print \"conv1 shape:\",conv1.shape\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "\t\t#print \"conv1 shape:\",conv1.shape\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\t\t#print \"pool1 shape:\",pool1.shape\n",
    "\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "\t\t#print \"conv2 shape:\",conv2.shape\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "\t\t#print \"conv2 shape:\",conv2.shape\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\t\t#print \"pool2 shape:\",pool2.shape\n",
    "\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "\t\t#print \"conv3 shape:\",conv3.shape\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "\t\t#print \"conv3 shape:\",conv3.shape\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\t\t#print \"pool3 shape:\",pool3.shape\n",
    "\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        drop4 = Dropout(0.5)(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "        up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "        merge6 = merge([drop4,up6], mode = 'concat', concat_axis = 3)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "        up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        merge7 = merge([conv3,up7], mode = 'concat', concat_axis = 3)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "        up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "        merge8 = merge([conv2,up8], mode = 'concat', concat_axis = 3)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "        up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "        merge9 = merge([conv1,up9], mode = 'concat', concat_axis = 3)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "        #group layers into model\n",
    "        model = Model(input = inputs, output = conv10)\n",
    "\n",
    "        model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "            print(\"loading data\")\n",
    "            \n",
    "            train = np.load('../../../../media/training3.npy').reshape([4507, 256, 256, 4]) \n",
    "            label = np.load('../../../../media/label3.npy').reshape([4507, 256, 256, 4])\n",
    "            \n",
    "            \n",
    "            n_input = train.shape[0]\n",
    "            n_channel = train.shape[3]\n",
    "            \n",
    "            imgs_train = train[0:int (n_input*0.8), :, :,:] / 255\n",
    "            imgs_test = train[int (n_input*0.8):n_input, :, :,:] / 255\n",
    "            imgs_mask_train = label[0:int (n_input*0.8), :, :,:]  / 255\n",
    "            imgs_test_label = label[int (n_input*0.8):n_input, :, :,:]  / 255\n",
    "            \n",
    "            #print(\"merging channels\")\n",
    "            #imgs_train = formSingleChannel(imgs_train)\n",
    "            #imgs_test1 = formSingleChannel(imgs_test)\n",
    "            \n",
    "            print(\"loading data done\")\n",
    "            model = self.get_unet()\n",
    "            #model = load_model(\"unet.hdf5\")\n",
    "            print(\"got unet\")\n",
    "            \n",
    "            model_checkpoint = ModelCheckpoint('../../../../media/unet.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "            print('Fitting model...')\n",
    "            model.fit(imgs_train, imgs_mask_train, batch_size=20, nb_epoch=10, verbose=1,validation_split=0.25, shuffle=True, callbacks=[model_checkpoint])\n",
    "            \n",
    "            print('predict test data')\n",
    "            imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "            np.save('../../../../media/imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b562ed37188020c8a8c07b69b9eae1a2662f56daf78cc992f9676fd3c0f765c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('2dunet': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

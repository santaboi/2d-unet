{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader , Dataset \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cfg import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use constantpad2d() to resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14041674', '29285707', '29729120', '15525495', '30871154', '28267864', '22296689', '27607264', '30920239', '16113441', '15176128', '31046225', '80190941', '28248060', '31445157', '29301889', '30268702', '11775010', '17244854', '13488672', '13661917', '28358688', '26434694', '12261283', '11009708', '18456622', '25825974', '26082459', '15552568', '26658418', '20947834', '27931321', '26608196', '19425238', '31001430', '27472711', '21372392', '26073373', '29177415', '29816081', '21381973', '24237245', '30517836', '27710844', '31406726', '30732894', '25385854', '27103788', '27237207', '21105320', '10027124', '18765851', '20483981', '19315335', '33056266', '52847319'}\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  currently using only nonPR (T1c)\n",
    "import os\n",
    "#non_T1C_data = \"./data/PSPF_voc_data/non_PR/T1c/JPEGImages/\" \n",
    "#non_T1C_target = \"./data/PSPF_voc_data/non_PR/T1c/SegmentationClassPNG/\" \n",
    "\n",
    "name_set = set()\n",
    "total_data_path = [non_T1C_data , PR_T1C_data , non_T1_data , PR_T1_data , non_Flair_data , PR_Flair_data , non_T2_data , PR_T2_data]\n",
    "for folder_name in total_data_path :\n",
    "    for name in os.listdir(folder_name) :\n",
    "        name = name.strip('.jpg').strip('.json')\n",
    "        if name == 'ipynb_checkpoint' :\n",
    "            continue\n",
    "        name_set.add(name)   \n",
    "#print(name_set)\n",
    "\n",
    "\n",
    "name_set2 = set()\n",
    "total_target_path = [PR_T1C_target , non_T1C_target , PR_T1_target , non_T1_target , PR_Flair_target , non_Flair_target , PR_T2_target , non_T2_target]\n",
    "for folder_name2 in total_target_path :\n",
    "    for name in os.listdir(folder_name2):\n",
    "        name = name.strip('.png')\n",
    "        if name == 'ipynb_checkpoint':\n",
    "            continue\n",
    "        name_set2.add(name)\n",
    "print(name_set2)\n",
    "\n",
    "\n",
    "#same patients set (make sure no mismatch)\n",
    "if name_set2 == name_set :\n",
    "    print('success')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torchvision.transforms as T \n",
    "\n",
    "class Total_dataset(Dataset):\n",
    "    def __init__(self, inputs: list, targets: list, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    def __getitem__(self , index : int  , transform = None):\n",
    "        #是否有辦法用path + file name取用data\n",
    "        input_img = self.inputs[index]\n",
    "        target_img = self.targets[index]\n",
    "        \n",
    "        x_data , y_data = cv2.imread(input_img) , cv2.imread(target_img)\n",
    "\n",
    "        if self.transform != None :\n",
    "            #x_data , y_data = self.transform(x_data , y_data)\n",
    "            for t in self.transform :\n",
    "                if t == T.Normalize() :\n",
    "                    pass\n",
    "                else :\n",
    "                    x_data = t(x_data)\n",
    "                    y_data =t(y_data)\n",
    "                \n",
    "        \n",
    "        if x_data.shape != [512 , 512 , 3] :\n",
    "            x_data = cv2.resize(x_data , (512 , 512))\n",
    "        if y_data.shape != [512 , 512 , 3] :\n",
    "            y_data = cv2.resize(y_data , (512 ,512))\n",
    "\n",
    "        # turn to torch (typecasting)\n",
    "        x_data, y_data = torch.from_numpy(x_data).type(torch.float32), torch.from_numpy(y_data).type(torch.float32)\n",
    "        return x_data , y_data  #torch\n",
    "\n",
    "        #torch or numpy to chose\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/PSPF_voc_data/non_PR/Flair/JPEGImages\\29285707.jpg\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'waitkey'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Temp/ipykernel_17608/3603889116.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"10\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mimg10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"10_2\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mimg10_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"**********\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'waitkey'"
     ]
    }
   ],
   "source": [
    " \n",
    "#same patient (same index)\n",
    "total_data_list = []\n",
    "total_target_list =[]  \n",
    "for name in name_set :\n",
    "    name1 = name + \".jpg\"\n",
    "    name2 = name + \".png\"\n",
    "    #total_data_list.append(non_T1C_data + name + '.jpg')\n",
    "    #total_target_list.append(non_T1C_target + name + '.png')\n",
    "    total_data_list.append(os.path.join(non_T1C_data , name1))\n",
    "    total_data_list.append(os.path.join(non_T1_data , name1))\n",
    "    total_data_list.append(os.path.join(non_Flair_data , name1))\n",
    "    total_data_list.append(os.path.join(non_T2_data , name1))\n",
    "    total_target_list.append(os.path.join(non_T1C_target , name , name2))\n",
    "    total_target_list.append(os.path.join(non_T1_target , name , name2))\n",
    "    total_target_list.append(os.path.join(non_Flair_target , name , name2))\n",
    "    total_target_list.append(os.path.join(non_T2_target , name , name2))\n",
    "\n",
    "    total_data_list.append(os.path.join(PR_T1C_data , name1))\n",
    "    total_data_list.append(os.path.join(PR_T1_data , name1))\n",
    "    total_data_list.append(os.path.join(PR_Flair_data , name1))\n",
    "    total_data_list.append(os.path.join(PR_T2_data , name1))\n",
    "    total_target_list.append(os.path.join(PR_T1C_target , name , name2))\n",
    "    total_target_list.append(os.path.join(PR_T1_target , name , name2))\n",
    "    total_target_list.append(os.path.join(PR_Flair_target , name , name2))\n",
    "    total_target_list.append(os.path.join(PR_T2_target , name , name2))\n",
    "print(total_data_list[10])\n",
    "img10 = cv2.imread(total_data_list[10])\n",
    "img10_2 = cv2.imread(\"./data/PSPF_voc_data/non_PR/Flair/JPEGImages/28358688.jpg\")\n",
    "cv2.imshow(\"10\" , img10)\n",
    "cv2.imshow(\"10_2\" , img10_2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(\"**********\")\n",
    "print(total_target_list)    \n",
    "\n",
    "train_data_list = total_data_list[0 : int(len(total_data_list)*0.8)] #80%data\n",
    "train_target_list =  total_target_list[0 : int(len(total_target_list)*0.8) ] #80%target\n",
    "\n",
    "test_data_list = total_data_list[int(len(total_data_list)*0.8) : len(total_data_list)] #20%data\n",
    "test_target_list = total_target_list[int(len(total_target_list)*0.8) : len(total_target_list)] #20%target\n",
    "\n",
    "\"\"\"#img visualize\n",
    "count , count2 = 0 , 0\n",
    "for img1 in train_data_list:\n",
    "    img1 = cv2.imread(img1)\n",
    "    plt.imshow(img1)\n",
    "    plt.show()\n",
    "    print(img1.shape)\n",
    "    count += 1\n",
    "    if count > 10 : break\n",
    "for img2 in target_data_list:\n",
    "    img2 = cv2.imread(img2)\n",
    "    plt.imshow(img2)\n",
    "    plt.show()\n",
    "    print(img2.shape)\n",
    "    count2 += 1\n",
    "    if count2 > 10: break\n",
    "\"\"\"\n",
    "\n",
    "#std and mean calculated\n",
    "#total dataset\n",
    "total_dataset = Total_dataset(total_data_list ,\n",
    "                              total_target_list,\n",
    "                              transform= None\n",
    ")\n",
    "total_dataloader = DataLoader(total_dataset , batch_size= len(total_dataset) , shuffle= False)\n",
    "x , y = next(iter(total_dataloader))\n",
    "print(\"x y mean0\" ,x[0].mean() , y[0].mean()) #ch1\n",
    "print(\"x y mean1\" ,x[1].mean() , y[1].mean()) #ch2\n",
    "print(\"x y mean2\" ,x[2].mean() , y[2].mean()) #ch3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#目前尚未 rescale 跟 normalize\n",
    "train_dataset = Total_dataset(train_data_list,\n",
    "                             train_target_list ,\n",
    "                             transform= T.Compose([T.ToTensor()])\n",
    "                            ) \n",
    "#transform should add                \n",
    "training_dataloader = DataLoader(train_dataset,\n",
    "                                 batch_size=10,\n",
    "                                 shuffle=True)\n",
    "\n",
    "test_dataset = Total_dataset(test_data_list ,\n",
    "                            test_target_list ,\n",
    "                            transform= None)\n",
    "                \n",
    "testing_dataloader = DataLoader(test_dataset,\n",
    "                                 batch_size=10,\n",
    "                                 shuffle=True)\n",
    "        \n",
    "train_x, train_y = next(iter(training_dataloader))\n",
    "test_x , test_y = next(iter(testing_dataloader))\n",
    "\n",
    "#img rescale\n",
    "\"\"\"imgs_train = train[0:int (n_input*0.8), :, :,:] / 255 \n",
    "imgs_test = train[int (n_input*0.8):n_input, :, :,:] / 255  \n",
    "imgs_mask_train = label[0:int (n_input*0.8), :, :,:]  / 255 \n",
    "imgs_test_label = label[int (n_input*0.8):n_input, :, :,:]  / 255 \"\"\"\n",
    "\n",
    "\n",
    "print(f'train_x = shape: {train_x.shape}; type: {train_x.dtype}')\n",
    "print(f'train_y = shape: {train_y.shape}; type: {train_y.dtype}')\n",
    "print(f'train_x = min: {train_x.min()}; max: {train_x.max()}')\n",
    "print(f'train_y = shape: {train_y.shape}; class: {train_y.unique()}; type: {train_y.dtype}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "#from data import *\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats.mstats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_10660/619793162.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_10660/619793162.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    def get_model(self):\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class Unet_model():\n",
    "    def __init__(self , img_row = 512 , img_col = 512):\n",
    "        self.img_row = img_row\n",
    "        self.img_col = img_col\n",
    "    \n",
    "    def get_model(self):\n",
    "\n",
    "        inputs = Input((self.img_rows, self.img_cols,3)) #3 channels\n",
    "\t\t\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "\t\t#print \"conv1 shape:\",conv1.shape\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "\t\t#print \"conv1 shape:\",conv1.shape\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\t\t#print \"pool1 shape:\",pool1.shape\n",
    "\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "\t\t#print \"conv2 shape:\",conv2.shape\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "\t\t#print \"conv2 shape:\",conv2.shape\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\t\t#print \"pool2 shape:\",pool2.shape\n",
    "\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "\t\t#print \"conv3 shape:\",conv3.shape\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "\t\t#print \"conv3 shape:\",conv3.shape\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\t\t#print \"pool3 shape:\",pool3.shape\n",
    "\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        drop4 = Dropout(0.5)(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "        up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "        merge6 = merge([drop4,up6], mode = 'concat', concat_axis = 3)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "        up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        merge7 = merge([conv3,up7], mode = 'concat', concat_axis = 3)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "        up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "        merge8 = merge([conv2,up8], mode = 'concat', concat_axis = 3)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "        up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "        merge9 = merge([conv1,up9], mode = 'concat', concat_axis = 3)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "        #group layers into model\n",
    "        model = Model(input = inputs, output = conv10)\n",
    "\n",
    "        model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "            print(\"loading data\")\n",
    "            \n",
    "            train = np.load('../../../../media/training3.npy').reshape([4507, 256, 256, 4]) \n",
    "            label = np.load('../../../../media/label3.npy').reshape([4507, 256, 256, 4])\n",
    "            \n",
    "            \n",
    "            n_input = train.shape[0]\n",
    "            n_channel = train.shape[3]\n",
    "            \n",
    "            imgs_train = train[0:int (n_input*0.8), :, :,:] / 255\n",
    "            imgs_test = train[int (n_input*0.8):n_input, :, :,:] / 255\n",
    "            imgs_mask_train = label[0:int (n_input*0.8), :, :,:]  / 255\n",
    "            imgs_test_label = label[int (n_input*0.8):n_input, :, :,:]  / 255\n",
    "            \n",
    "            #print(\"merging channels\")\n",
    "            #imgs_train = formSingleChannel(imgs_train)\n",
    "            #imgs_test1 = formSingleChannel(imgs_test)\n",
    "            \n",
    "            print(\"loading data done\")\n",
    "            model = self.get_unet()\n",
    "            #model = load_model(\"unet.hdf5\")\n",
    "            print(\"got unet\")\n",
    "            \n",
    "            model_checkpoint = ModelCheckpoint('../../../../media/unet.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "            print('Fitting model...')\n",
    "            model.fit(imgs_train, imgs_mask_train, batch_size=20, nb_epoch=10, verbose=1,validation_split=0.25, shuffle=True, callbacks=[model_checkpoint])\n",
    "            \n",
    "            print('predict test data')\n",
    "            imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "            np.save('../../../../media/imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b562ed37188020c8a8c07b69b9eae1a2662f56daf78cc992f9676fd3c0f765c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('2dunet': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
